% TODO?: Adicionar subseção de modelagem do problema

% TODO?: Usar a metodologia do Fábio como inspiração

% TODO: Incluir métricas de precisão

% TODO?: Falar sobre a especificação do ambiente

Este capítulo tem como objetivo explicar como foram realizadas as comparações dos modelos quanto as suas predições. Primeiramente será discutido os pré-processamentos dos dados, seguindo para os modelos, incluindo a razão por estes terem sido incluídos. Logo após será discutido como as otimizações foram feitas e como fora feita a avaliação dos modelos.

\section{Pré-Processamento dos Dados}
% TODO: Adicionar gráfico (fluxo por tempo) em tratamento de dados.

Nesta etapa serão feitas remoções e transformações dos dados mostrados na Tabela \ref{table:data} para melhorar o aprendizado dos modelos.

\subsection{Limpeza dos Dados}
% TODO?: Botar hora no multivariate

Nem todas as colunas são úteis para o aprendizado dos modelos, em especial, as colunas \texttt{Faixa}, \texttt{Hora}, \texttt{Limite de Velocidade da Via} e \texttt{Tamanho do Veículo}. \texttt{Faixa} será removido, pois nas transformações que virão a seguir esse dado se tornará desnecessário. \texttt{Hora} será removido, pois para ter algum efeito positivo no aprendizado dos modelos, seria preciso um estudo mais minucioso. \texttt{Limite de Velocidade da Via} será removido, pois este dado tem seu valor repetido ao longo de todos os registros, ou seja, é uma constante em todo o conjunto de dados. \texttt{Tamanho do Veículo} será removido, pois este não foi medido de forma precisa, visto que existem registros com veículos de tamanho nulo.


\subsection{Transformação dos Dados}

% TODO: Adicionar referencia do one hot enconding 
% https://www.researchgate.net/publication/320465713_A_Comparative_Study_of_Categorical_Variable_Encoding_Techniques_for_Neural_Network_Classifiers

% TODO: Explicar melhor como o one-hot-encoding melhora

Caso fosse utilizado a coluna \texttt{Data} sem tratamento, ficaria a cargo dos modelos implementados extrair muitos dos significados por trás da mesma. Isto é, qual o dia da semana e o dia do mês referente àquela data, a qual a estação do ano aquele dia específico pertence. Então, para facilitar o aprendizado e evitar falsas suposições foi utilizado o método \textit{one-hot encoding} para transformar a coluna de \texttt{Data} em 7 colunas \textit{booleanas} que representam os dias da semana. Este tipo de tratamento se torna necessário devido ao fato de que o dia da semana é uma variável qualitativa e, caso fosse representada como quantitativa, (0 como domingo e 1 como segunda, por exemplo) o modelo poderia realizar inferências, como "segunda" é maior que "quarta", ou algo similar. Mais sobre \textit{one-hot encoding} pode ser visto em [CITACAO ONE HOT ENCONDING].

\subsection{Acumulação dos registros}

O tráfego pode ser interpretado de várias formas diferentes. Pode ser visto como a quantidade de veículos que passaram por um ponto em um determinado intervalo de tempo, ou seja, o fluxo. Também pode ser visto como o fluxo dividido pela média de velocidade dos veículos em um certo espaço de tempo, ou seja, a densidade. Ou como uma média de velocidade em um intervalo de tempo, a velocidade média.

% TODO: conferir isso
Como grande parte da literatura acerca da previsão de fluxo de veículos utiliza o fluxo para fazer o treinamento de suas redes neurais, também optamos por utilizá-lo. Além disso, como o domínio dos valores do nosso fluxo é menor que o domínio dos valores da densidade e da velocidade média, nossos modelos tendem a ter uma maior facilidade para realizar a previsão.
%Para o nosso trabalho escolhemos utilizar o fluxo, pois seus valores estão inclusos no conjunto dos números inteiros positivos. Já os outros jeitos de ver o tráfego tem seus valores inclusos no conjunto dos números naturais. Como o domínio do fluxo é menor que os outros, os modelos tem uma maior facilidade de fazer a previsão.

% TODO: Falar que aproveitamos e adicionamos no multivariado a densidade e a velocidade média
Sendo assim, iremos transformar o conjunto de dados de uma série temporal de registro de veículos para uma série temporal de fluxos. Isto é, iremos calcular a quantidade de veículos que passaram por um local em um determinado intervalo de tempo. Para definir o intervalo que utilizaríamos, testamos os valores de intervalo para 1, 2.5, 5 e 7.5 minutos. No caso, os melhores resultados foram com a acumulação dos registros em um intervalo de 7.5 minutos. Isso se deve, em parte, ao fato de que quando se acumula os registros em um intervalo de tempo muito pequeno, o conjunto de dados apresenta muito ruído, dificultando a aprendizagem e afetando a qualidade da previsão. Em contrapartida, ao se aumentar o intervalo, o conjunto de dados pode se tornar muito pequeno, o que pode dificultar a aprendizagem. Tendo isso em mente, 7.5 minutos teve o melhor resultado, pois como nossa primeira previsão é para 15 minutos no futuro, não poderíamos utilizar um intervalo que não fosse divisor de 15, nem maior que 15. Ao final da transformação, temos um conjunto de dados similar ao mostrado na Tabela \ref{table:data_pre}.

\begin{table}[h]
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{1}{l}{\textbf{Flow}} & \multicolumn{1}{l}{\textbf{Density}} & \multicolumn{1}{l}{\textbf{Average Speed}} & \multicolumn{1}{l}{\textbf{Sun}} &
    \multicolumn{1}{l}{\textbf{Mon}} & \multicolumn{1}{l}{\textbf{Tue}} & \multicolumn{1}{l}{\textbf{Wed}} & \multicolumn{1}{l}{\textbf{Thu}} &
    \multicolumn{1}{l}{\textbf{Fri}} &
    \multicolumn{1}{l}{\textbf{Sat}} \\
    \midrule
     6 & 0.260870 & 23.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    17 & 0.586207 & 29.235294 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    15 & 0.625000 & 24.933333 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    18 & 0.666667 & 27.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    14 & 0.736842 & 19.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    14 & 0.700000 & 20.571429 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     6 & 0.352941 & 17.833333 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.400000 & 20.375000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    11 & 0.550000 & 20.181818 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    15 & 0.652174 & 23.466667 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    10 & 0.588235 & 17.700000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    13 & 0.722222 & 18.769231 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    11 & 0.785714 & 14.363636 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.400000 & 20.125000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.347826 & 23.750000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \bottomrule
    \end{tabular}
    \label{table:data_pre}
    \caption{Amostra do pré-processamento dos dados ao se utilizar 7.5 minutos de intervalo do sensor RSI128}
\end{table}

No final do pré-processamento o resultado possuirá 3 colunas quantitativas e 7 qualitativas. As colunas de \textit{Density} e \textit{Average Speed} são contínuas e a coluna \textit{Flow} é discreto. As outras 7 colunas representam uma classificação indicando é ou não (0 representa falso e 1 verdadeiro) um certo dia da semana, sendo assim uma coluna qualitativa ordinal.

\subsection{Normalização dos Dados}
% TODO: Falar o motivo do porque se normaliza
% TODO: Justificar o porquê não normalizamos os dados
%TODO: Checar o maior e o menor valor de fluxo calculado 
Na área de aprendizagem de máquina, é comum vermos modelos de predições para diferentes tipo de variáveis. Por vezes, os valores assumidos por essas variáveis podem apresentar um domínio grande demais, como no caso da predição de valores de ações da bolsa de valores. Com valores em um intervalo tão grande, o treinamento dos modelos tende a piorar. Para contornar este problema, é comum utilizar técnicas que visam diminuir o intervalo de valores que as variáveis podem assumir. Uma destas técnicas é a normalização. Em um dos tipos da normalização, utiliza-se o maior e o menor valor que o seu conjunto de dados atinge para ajustar os valores intermediários. No nosso deste trabalho, o maior fluxo calculado foi 60 e o menor foi 20. Assim, ajustamos os valores do conjunto de dados dentro de um intervalo entre 0 e 1, com 0 representando o menor valor e 60, o maior valor. 

Além disso, em função do modo de como alguns dos modelos funcionam, como o \textit{\acrshort{LSTM}}, serão utilizados as versões normalizados dos conjuntos de dados para tornar mais efetivo o treinamento dos mesmos. Vale notar que ao normalizar, a coluna de \textit{Flow} se tornou quantitativa contínua.

\begin{table}[h]
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{1}{l}{\textbf{Flow}} & \multicolumn{1}{l}{\textbf{Density}} & \multicolumn{1}{l}{\textbf{Average Speed}} & \multicolumn{1}{l}{\textbf{Sun}} &
    \multicolumn{1}{l}{\textbf{Mon}} & \multicolumn{1}{l}{\textbf{Tue}} & \multicolumn{1}{l}{\textbf{Wed}} & \multicolumn{1}{l}{\textbf{Thu}} &
    \multicolumn{1}{l}{\textbf{Fri}} &
    \multicolumn{1}{l}{\textbf{Sat}} \\
    \midrule
    0.063830 & 0.081838 & 0.412281 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.180851 & 0.186387 & 0.512900 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.159574 & 0.192835 & 0.437427 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.191489 & 0.209804 & 0.482456 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.148936 & 0.230127 & 0.342105 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.148936 & 0.218141 & 0.360902 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.063830 & 0.107843 & 0.312865 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.085106 & 0.125854 & 0.357456 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.117021 & 0.174705 & 0.354067 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.159574 & 0.204887 & 0.411696 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.106383 & 0.181093 & 0.310526 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.138298 & 0.222009 & 0.329285 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.117021 & 0.245472 & 0.251994 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.085106 & 0.127417 & 0.353070 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \midrule
    0.085106 & 0.107969 & 0.416667 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 \\
    \bottomrule
    \end{tabular}
    \label{table:data_pre_norm}
    \caption{Amostra do pré-processamento normalizado dos dados ao se utilizar 7.5 minutos de intervalo do sensor RSI128}
\end{table}

\subsection{Sazonalidade dos Dados}


\subsection{Produção dos Conjunto de Dados}

Para fins de análise, utiliza-se o conjunto de dados pré processados para gerar um outro conjunto de dados mais simples. Este conjunto mais seimples possuirá somente o fluxo, permitindo assim verificar se as variáveis escolhidas (\textit{Velocidade Média} e \textit{Dia da Semana}) melhoram a performance do modelo. Deste modo, tem-se um conjunto de dados uni-variado, isto é, possuirá somente uma variável, o fluxo. E o outro será multi-variado, isto é, possuirá várias variáveis, sendo elas o fluxo, a velocidade média no intervalo e o dia da semana.

\section{Modelos}

Visto que a predição do fluxo é o foco do trabalho e que que o fluxo é quantitativo, serão utilizados modelos de regressão para encontrar um padrão nos dados. Ou seja, serão utilizados modelos guiados por dados. Segundo o artigo \textit{Short-Term Travel-Time Prediction on Highway: A Review of the Data-Driven Approach} por Simon Oh et. al. \cite{parametric}, estes modelos podem ser classificados em dois grupos: paramétricos e não-paramétricos. Modelos paramétricos usam um número fixo de parâmetros para tentar descrever os dados, assumindo assim que os dados seguem uma distribuição específica. Um exemplo de modelo paramétrico seria a regressão linear, que utiliza uma equação com parâmetros fixos para traçar uma reta que melhor representa a distribuição dos dados. Já modelos não-paramétricos possuem um número variável de parâmetros que dependem dos dados utilizados. Assim, não assumindo uma distribuição específica nos dados.

% TODO: Adicionar referencia para mostrar que o ARIMA é um dos mais utilizados
Dos modelos paramétricos, o mais utilizado na literatura para previsão de fluxo é o \textit{\acrfull{ARIMA}} e suas variações, além de modelos mais simples como \textit{\acrfull{LR}}. Dos modelos não-paramétricos, se destacam o \textit{\acrfull{LSTM}} e o \textit{\acrfull{GRU}}, sendo ambos \textit{\acrshort{RNN}}'s.

% TODO: falar que estamos utilizando um modelo para cada tipo de viés (rf para arvores, etc)

Todos os modelos não-paramétricos citados foram implementados para este trabalho. Quanto aos modelos paramétricos, foram testados dois modelos, sendo eles o \textit{\acrshort{ARIMA}} e o \textit{\acrshort{LR}}. Porém, ambos tiveram resultados inferiores em relação aos modelos não-paramétricos testados. Além disso, \textit{\acrshort{ARIMA}} se mostrou extremamente custosos computacionalmente de se treinar e otimizar. Por estes dois motivos citados, os modelos paramétricos foram retirados dos experimentos.

\subsection{Entrada}

Devido ao custo computacional, seria inviável treinar e fazer previsões com um número muito grande de fluxos do passado. Baseado nisso, utilizamos somente uma quantidade fixa referente a algumas horas no passado.

%TODO: EXPLICAR NAIVE
\subsection{Modelos de Comparação}

Serão utilizados também dois modelos com o único propósito de estabelecer uma base de comparação inicial para os outros modelos. Serão eles o \textit{Naive} e \textit{Moving Average}. O primeiro faz suas predições apenas escolhendo aleatoriamente um número de 0 até o maior número do nosso conjunto de dados. Dessa forma, é possível colocar em perspectiva o desempenho dos outros modelos e analisar se eles estão melhores do que um modelo que simplesmente escolhe valores possíveis ao acaso. Já o segundo faz a média dos valores da entrada, o que seria o método mais simples depois de escolher valores aleatórios.

\subsection{Implementação}

As arquiteturas utilizadas neste trabalho foram implementados na linguagem \textit{Python} utilizando bibliotecas como \textit{Keras} com \textit{TensorFlow} e \textit{SKLearn}. Decidiu-se por utilizar essas bibliotecas, pois suas implementações já são robustas, otimizadas e bem testadas. Implementar todos os modelos sem o auxílio de nenhuma biblioteca seria ineficiente para objetivo dos experimentos e prono a erros. Além disso, o uso das bibliotecas facilita a reprodução dos experimentos para os interessados em avançar ou verificar este projeto.

\textit{Keras} foi utilizado para implementar os modelos de \acrshort{RNN}, \acrshort{LSTM} e \acrshort{GRU} e optou-se por usar como base dessa biblioteca o \textit{TensorFlow}, visto que este é o \textit{framework} com suporte para aprendizado de máquina mais utilizado dentre os desenvolvedores, segundo um \textit{survey} feito em 2018 pelo \textit{StackOverflow} \cite{stack_2018}. Já \textit{SKLearn} foi utilizado para implementar os modelos \acrshort{RF} e \acrshort{SVM}. Além disso, utilizou-se a biblioteca \textit {Hyperas} para a escolha dos melhores valores para cada um dos hiper-parâmetros.

\section{Escolha de Parâmetros e Hiper-Parâmetros}

Para a escolha dos parâmetros e hiper-parâmetros será feito uma busca dos melhores para cada modelo. 

Para os modelos de aprendizagem profunda, isto é, \textit{\acrshort{RNN}}, \textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}} será utilizada a biblioteca \textit{Hyperas} que já possui integração com a biblioteca \textit{Keras}. Os parâmetros e hiper-parâmetros escolhidos foram:

% TODO: Explicar para que serve cada parametro

\begin{itemize}
    \item \textbf{Tamanho do \textit{Batch}:} 1, 32 e 64; \newline
    O tamanho do batch serve para...
    \item \textbf{Otimizador do Modelo:} Adam;
    \item \textbf{Função de Ativação:} Sigmoid, Relu;
    \item \textbf{Quantidade de Células:} 20, 30, 40;
\end{itemize}

Para os modelos tradicionais, isto é, \textit{\acrshort{SVM}} e \textit{\acrshort{RF}} será utilizado da técnica de \textit{Grid Search}. Para a \textit{\acrshort{SVM}} foram escolhidos os parâmetros:

\begin{itemize}
    \item \textbf{Gamma:} Scale;
    \item \textbf{C:} 1.0;
    \item \textbf{Epsilon:} 0.2;
\end{itemize}

Já os parâmetros escolhidos para \textit{\acrshort{RF}} foram:

\begin{itemize}
    \item \textbf{Número de Estimadores:} 100 a 1000 de 100 em 100;
    \item \textbf{\textit{Bootstrap}:} Ativado e Desativado;
\end{itemize}

\section{Avaliação Final}
% TODO: Justificar que não podemos usar MAPE como avaliação, pois nosso dataset inclui zeros (https://stats.stackexchange.com/questions/280464/is-mape-a-good-error-measurement-statistic-and-what-alternatives-are-there)

% TODO: worth a reading to complement the reason why we use normalised version (https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization)

% TODO: Explicar porque tem que ser utilizado janela deslizante em séries temporais, onde acho um artigo sobre isso?

% TODO: Falar das principais métricas usadas na literatura e colocar a referência.

Visto que os dados deste trabalho são séries temporais, realizou-se vários testes utilizando uma janela deslizante. Desta forma, foi possível testar os modelos sobre um conjunto de testes maior. Dessa forma, foi possível ter uma análise melhor de como os modelos se comportam com diferentes janelas de treinamento e teste. Todos os modelos serão treinados e testados com os mesmos subconjuntos de dados, para fins de comparação. Como métricas, fora utilizados \acrshot{MAE}, \acrshort{RMSE} e \acrshort{NRMSE}. 

\begin{equation}
MAE = \frac{1}{n} \times \sum_{i=1}^{n} \quad \abs{result_i - expected_i}
\end{equation}

\begin{equation}
RMSE = \sqrt{ \frac{1}{n} \times \sum_{i=1}^{n} \quad (result_i - expected_i) ^ 2}
\end{equation}

\begin{equation}
\sigma = \sqrt{ \frac{1}{n} \times \sum_{i=1}^{n} \quad (result_i - \overline{result}) ^ 2}
\end{equation}

\begin{equation}
NRMSE = \frac{RMSE(result, expected)}{\sigma(expected)}
\end{equation}

As duas primeiras métricas podem ser encontradas na literatura para avaliação dos modelos de predição de fluxo, a última é uma métrica utilizada para permitir comparações entre modelos que usam conjunto de dados diferentes, visto que ao ser normalizado ele perde a correlação com o conjunto de dados. Essas medições serão feitas para cada tempo de previsão discutido.