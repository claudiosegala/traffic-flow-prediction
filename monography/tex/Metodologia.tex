% TODO?: Usar a metodologia do Fábio como inspiração

% TODO: Incluir métricas de precisão

% TODO?: Falar sobre a especificação do ambiente

Este capítulo tem como objetivo explicar como foram realizadas as comparações dos modelos quanto as suas predições, assim como mostrado na Figura \ref{figure:metodologia}. Primeiramente será discutido os pré-processamentos dos dados, seguindo para os modelos, incluindo a razão por estes terem sido incluídos. Logo após será discutido como as otimizações foram feitas e como fora feita a avaliação dos modelos.

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{monography/img/tccFlux.png}
    \label{figure:metodologia}
    \caption[Fluxograma da metodologia]{Fluxograma da metodologia}
\end{figure}

\section{Ambiente de Experimento}
% TODO: get more information about this

O ambiente de experimento foi um servidor equipado com Ubuntu. O servidor possui dois CPUs \textit{Intel(R) Xeon(R) Platinum 8160 CPU @ 2.10GHz} e 251 GiB de memória principal.

\section{Pré-Processamento dos Dados}

Nesta etapa serão feitas remoções de inconsistências e transformações nos dados da Tabela \ref{table:data} para melhorar o aprendizado dos modelos. Assim como também será mostrado como os conjuntos de dados para treinamento e teste foram definidos.

\subsection{Limpeza dos Dados}

Para realizar a limpeza dos dados, as colunas que não são relevantes para o treinamento dos modelos serão removidas. São elas:

\begin{itemize}
    \item \texttt{Faixa}
    \item  \texttt{Hora}
    \item \texttt{Limite de Velocidade da Via}
    \item  \texttt{Tamanho do Veículo}
\end{itemize}

A coluna \texttt{Faixa} será removida, pois nas transformações que virão a seguir, esse dado se tornará desnecessário, visto que o objetivo deste trabalho é prever o fluxo na via como um todo e não em faixas específicas. A coluna \texttt{Hora} será removida, pois com o intervalo de fluxo, já é possível saber a qual momento do dia se refere determinado registro. Além disso, para utilizar a hora propriamente dita como entrada dos modelos, seria necessária uma análise mais minuciosa de como tratá-la, o que foge do escopo definido pelo trabalho. A coluna \texttt{Limite de Velocidade da Via} será removida, pois este dado tem seu valor repetido ao longo de todos os registros, ou seja, é uma constante em todo o conjunto de dados e não afeta no treinamento dos modelos. A coluna \texttt{Tamanho do Veículo} será removida, pois não foi medida de forma precisa, visto que existem registros com veículos de tamanho zero (o que não é fisicamente possível).

\subsection{Transformação dos Dados}

A transformação dos dados se torna necessária nas colunas cujo o valor representado por elas pode gerar ambiguidade. Isto é, pode causar interpretações que não são necessariamente verdade. Tome como exemplo a coluna \texttt{Data}: Caso fosse utilizada sem tratamento nos modelos, ficaria a cargo dos mesmos extrair muitos dos significados por trás dos seus valores. Como por exemplo: qual o dia da semana e o dia do mês referente àquela data? A qual a estação do ano aquele dia específico pertence? Então, para facilitar o aprendizado e evitar falsas suposições, foi utilizado o método \textit{one-hot encoding} para transformar a coluna de \texttt{Data} em 7 colunas \textit{booleanas} que representam os dias da semana. Este tipo de tratamento se torna necessário devido ao fato de que o dia da semana é uma variável qualitativa e, caso fosse representada como quantitativa, (0 como domingo e 1 como segunda, por exemplo) o modelo poderia realizar inferências, como "segunda" é maior que "quarta", ou analogias similares.

\subsection{Acumulação dos registros}

% TODO: mAdicionar referencia de artigos que usem fluxo para fazer prediçao.
Como visto na literatura, existem algumas maneiras de se fazer a predição de veículos em uma via. Seja pelo fluxo, pela densidade, ou pela velocidade média dos carros, por exemplo. Neste trabalho, optou-se por utilizar o fluxo como método de predição.

% TODO: Falar que aproveitamos e adicionamos no multivariado a densidade e a velocidade média
Sendo assim, será transformado o conjunto de dados de uma série temporal de registro de veículos para uma série temporal de fluxos. Isto é, será calculado a quantidade de veículos que passaram por um local em um determinado intervalo de tempo. Para definir o intervalo que utilizado, testou-se os valores de intervalo para 1, 2.5, 5 e 7.5 minutos. Note que foram utilizados intervalos que sejam múltiplos de 15, visto que todos os tempos de predição no futuro serão múltiplos de 15.

Após os testes, constatou-se que os melhores resultados foram com a acumulação dos registros em um intervalo de 7.5 minutos. Isso se deve, em parte, ao fato de que quando se acumula os registros em um intervalo de tempo muito pequeno, o conjunto de dados apresenta muito ruído, dificultando a aprendizagem e afetando a qualidade da previsão. Em contrapartida, ao se aumentar o intervalo, o conjunto de dados pode se tornar muito pequeno, o que pode dificultar a aprendizagem. Visto isso, observou-se que 7.5 minutos obteve o resultado mais equilibrado, pois como a primeira previsão é para 15 minutos no futuro, não poderia ser utilizado um intervalo que não fosse divisor de 15, nem maior que 15. Ao final da transformação, tem-se um conjunto de dados similar ao mostrado na Tabela \ref{table:data_pre}. Abaixo também pode ser observado parte do código responsável por realizar esta transformação:

\begin{lstlisting}[language=Python, caption = GetFlow Python Function]
def get_flow (data, flow_interval, normalize, verbosity):
  date = np.asarray(data['Date'])
  weekDay = np.asarray(data['WeekDay'])
  time = np.asarray(data['Time'])
  speed = np.asarray(data['Speed'])
  
  dateControl = date[0]
  timeBlock = flow_interval
  countFlow = 0
  accSpeed = 0
  flowData = []

  for i in range(len(date)):
    if time[i] >= timeBlock: # init a new time block
      flowData.append(get_flow_data(countFlow, accSpeed, weekDay[i])) 
      timeBlock += flow_interval
      accSpeed = 0
      countFlow = 0
      
    if date[i] > dateControl: # reset on day change
      dateControl = date[i]
      timeBlock = flow_interval 
      countFlow = 0
      accSpeed = 0
      
    if time[i] < timeBlock: # add car on flow
      countFlow += 1
      accSpeed += speed[i]

  return flowData

\end{lstlisting}

\begin{table}[H]
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{1}{l}{\textbf{Flow}} & \multicolumn{1}{l}{\textbf{Density}} & \multicolumn{1}{l}{\textbf{Average Speed}} & \multicolumn{1}{l}{\textbf{Sun}} &
    \multicolumn{1}{l}{\textbf{Mon}} & \multicolumn{1}{l}{\textbf{Tue}} & \multicolumn{1}{l}{\textbf{Wed}} & \multicolumn{1}{l}{\textbf{Thu}} &
    \multicolumn{1}{l}{\textbf{Fri}} &
    \multicolumn{1}{l}{\textbf{Sat}} \\
    \midrule
     6 & 0.260870 & 23.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    17 & 0.586207 & 29.235294 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    15 & 0.625000 & 24.933333 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    18 & 0.666667 & 27.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    14 & 0.736842 & 19.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    14 & 0.700000 & 20.571429 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     6 & 0.352941 & 17.833333 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.400000 & 20.375000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    11 & 0.550000 & 20.181818 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    15 & 0.652174 & 23.466667 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    10 & 0.588235 & 17.700000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    13 & 0.722222 & 18.769231 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    11 & 0.785714 & 14.363636 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.400000 & 20.125000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.347826 & 23.750000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \bottomrule
    \end{tabular}
    \label{table:data_pre}
    \caption{Amostra do pré-processamento dos dados ao se utilizar 7.5 minutos de intervalo do sensor RSI128}
\end{table}

No final do pré-processamento o resultado possuirá 3 colunas quantitativas e 7 qualitativas. As colunas de \textit{Density} e \textit{Average Speed} são contínuas e a coluna \textit{Flow} é discreto. As outras 7 colunas representam uma classificação indicando se é ou não (0 representa falso e 1 verdadeiro) um certo dia da semana, sendo assim uma coluna qualitativa ordinal.

Vale notar que como o período é o mesmo para qualquer dos sensores, ao se acumular os registros, o tamanho do conjunto de dados será o mesmo. Isto é, será equivalente ao intervalo de tempo do conjunto de dados, 92 dias, divido pelo tempo de agregação, 7.5 minutos, o que gera 17.664 registros de fluxo dos 536.879 registros de passagem de veículos.

\subsection{Sazonalidade dos dados}


Na Figura \ref{figure:flow_discution} é mostrado o resultado da agregação dos registros de veículos em um intervalo de 7.5 minutos. É possível observar que existem flutuações na quantidade de fluxo de veículo de acordo com o dia. Este fato fica mais evidente se observarmos o primeiro pico do gráfico, referente ao Domingo, pois este apresenta um menor fluxo de veículos, o que é esperado que aconteça em um dia não comercial. Isso mostra que os dados apresentam certa sazonalidade. Esta sazonalidade se manifesta em várias escalas, no gráfico mostrado é possível ver apenas a sazonalidade referente aos dias da semana, mas ela também se aplica, por exemplo, a semana do mês, ao mês do ano, etc. Por este motivo, o escopo deste trabalho foi definido apenas para os 3 meses de dados disponíveis. 


\begin{figure}
    \centering
    \includegraphics[scale=1]{monography/img/flows/flow_450_week_01.png}
    \label{figure:flow_discution}
    \caption[Fluxo da Primeira Semana]{Fluxo da Primeira Semana}
\end{figure}

\subsection{Normalização dos Dados}
% TODO: adicionar referência do porque normalizar dados
Na área de aprendizagem de máquina, é comum vermos modelos de predições para diferentes tipo de variáveis. Por vezes, os valores assumidos por essas variáveis podem apresentar um domínio grande demais, como no caso da predição de valores de ações da bolsa de valores. Com valores em um intervalo tão grande, o treinamento dos modelos tende a piorar. Para contornar este problema, é comum utilizar técnicas que visam diminuir o intervalo de valores que as variáveis podem assumir. Uma destas técnicas é a normalização. 

Em um dos tipos da normalização, utiliza-se o maior e o menor valor que o seu conjunto de dados atinge para ajustar os valores intermediários. Por exemplo, o maior fluxo calculado foi 94 veículos para o sensor \textbf{RSI128} com acumulação de 7,5 minutos e o menor foi 0. Assim, ajustamos os valores do conjunto de dados dentro de um intervalo entre 0 e 1, com 0 representando o menor valor e 60, o maior valor. Porém, nos nosso testes a normalização piorou os resultados, então decidimos continuar sem normalização.

\subsection{Produção dos Conjunto de Dados}

Será utilizado o conjunto de dados pré-processados para gerar o conjunto de dados de treino e teste. Cada elemento do conjunto de treino será série temporal de atributos. Ou seja, cada elemento de treino terá \(n\) instâncias do passado, cada instância será uma das linhas da Tabela \ref{table:data_pre_norm}. Para o conjunto de testes, cada elemento será o fluxo corresponde no futuro.

% TODO: adicionar imagem ou formulas matemáticas para melhorar o entendimento

Para se adaptar aos modelos, serão gerados duas versões do conjunto de dados de treino e teste. Uma versão será para os modelos tradicionais (\textit{\acrshort{RF}} e \textit{\acrshort{SVM}}), que terá somente duas dimensões (amostras por atributos) e a outra para os modelos de aprendizagem profunda (\textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}}) com três dimensões (amostras por passos por atributos).

Para fins de análise, utiliza-se o conjunto de dados de treino para gerar um outro conjunto de dados de treino mais simples. Este conjunto mais simples possuirá somente o fluxo, permitindo assim verificar se as colunas de \texttt{VelocidadeMédia}, \texttt{Density} e as de dias da semana melhoram a performance do modelo. Deste modo, tem-se um conjunto de dados uni-variado, isto é, possuirá somente um tipo de variável, o fluxo. E o outro será multi-variado, isto é, possuirá vários tipos de variáveis, sendo elas o fluxo, a velocidade média no intervalo e o dia da semana.

\section{Modelos}

Visto que a predição do fluxo é o foco do trabalho, que temos um conjunto de pares entrada e saída, e que que o fluxo é quantitativo. Será utilizado técnicas de aprendizagem de máquina supervisionadas de regressão para prever a curto prazo o fluxo da via. Dentre essas técnicas, podemos dividi-las novamente em paramétricos e não-paramétricos.

Dos modelos não-paramétricos, se destacam o \textit{\acrfull{LSTM}} e o \textit{\acrfull{GRU}}, sendo ambos \textit{\acrshort{RNN}}'s. Quanto ao \textit{\acrfull{LSTM}}, vale ressaltar que existem diversas variações e implementações. Porém, como Greff et al mostrou em \cite{Greff_2015}, as enormes variedades de \textit{\acrshort{LSTM}} não possuem tantas diferenças quanto a qualidade de suas previsões. Por este motivo, este trabalho utilizou o \textit{\acrfull{LSTM}} comum. Dos modelos paramétricos, o mais utilizado na literatura para previsão de fluxo é o \textit{\acrfull{ARIMA}} e suas variações \cite{doi:10.1080/01441647.2014.992496}, além de modelos mais simples como \textit{\acrfull{LR}}. 

% TODO: falar que estamos utilizando um modelo para cada tipo de viés (rf para arvores, etc)

Todos os modelos não-paramétricos citados foram implementados para este trabalho. Quanto aos modelos paramétricos, foram testados dois modelos, sendo eles o \textit{\acrshort{ARIMA}} e o \textit{\acrshort{LR}}. Porém, ambos tiveram resultados inferiores em relação aos modelos não-paramétricos testados, sendo que ambos estavam utilizando os parâmetros padrões da biblioteca \textit{StatModels}. Além disso, \textit{\acrshort{ARIMA}} se mostrou extremamente custosos computacionalmente de se treinar e otimizar. Por estes dois motivos citados, os modelos paramétricos foram retirados dos experimentos.

\subsection{Modelos de Comparação}

Serão utilizados também dois modelos com o único propósito de estabelecer uma base de comparação inicial para os outros modelos. Serão eles o \textit{Naive} e \textit{Moving Average}. O primeiro faz suas predições apenas escolhendo o valor de fluxo mais recente dos que recebeu de entrada. Já o segundo faz a média dos valores de fluxo recebidos na entrada. Dessa forma, é possível colocar em perspectiva o desempenho dos modelos escolhidos. Também fora implementado o \textit{Random Guess} cujo respondia aleatoriamente para qualquer entrada (valores entre o menor e maior elemento encontrado no conjunto), porém este era muito inferior e decidimos retirá-lo.

\subsection{Implementação}

As arquiteturas utilizadas neste trabalho foram implementados na linguagem \textit{Python} utilizando bibliotecas como \textit{Keras} com \textit{TensorFlow} e \textit{SKLearn}. Decidiu-se por utilizar essas bibliotecas, pois suas implementações já são robustas, otimizadas e bem testadas. Implementar todos os modelos sem o auxílio de nenhuma biblioteca seria ineficiente para objetivo dos experimentos e prono a erros. Além disso, o uso das bibliotecas facilita a reprodução dos experimentos para os interessados em avançar ou verificar este projeto.

\textit{Keras} foi utilizado para implementar os modelos de \textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}} e optou-se por usar como base dessa biblioteca o \textit{TensorFlow}, visto que este é o \textit{framework} com suporte para aprendizado de máquina mais utilizado dentre os desenvolvedores, segundo um questionário feito em 2018 pelo \textit{Stack Overflow} \cite{stack_2018}. Já \textit{SKLearn} foi utilizado para implementar os modelos \acrshort{RF} e \acrshort{SVM}. Além disso, utilizou-se a biblioteca \textit {SKLearn} para realizar uma pesquisa dos melhores parâmetros e hiper-parâmetros.

\subsection{Escolha de Parâmetros e Hiper-Parâmetros}

Tanto os modelos quando o conjunto de treinamento podem ser ajustados para servir mais ao problema. Sendo assim, esse trabalho realiza testes para tentar melhorar a predição dos modelos. Primeiramente será feito a escolha dos parâmetros para determinar, dentre as opções escolhidas, quais os melhores parâmetros de ajuste do conjunto de treinamento. Subsequentemente será feita a escolha dos hiper-parâmetros que varia de modelo para modelo. Vale notar que as opções a serem testadas precisam lidar com limitações de hardware.

A escolha de parâmetros será feita assumindo que os parâmetros são independentes. Elas são o passado visível, o número de divisões do conjunto de dados e o tamanho do intervalo do fluxo. O passado visível determina o tamanho do entrada, o número de divisões afeta o tamanho das amostras de treino e teste e o tamanho do intervalo do fluxo altera o tamanho do conjunto de dados de uma forma geral. Na literatura a escolha de parâmetros é empírica e baseada no problema, sendo assim baseamos no nosso problema para determinar os valores a serem testados, sendo eles:

\begin{itemize}
    \item \textbf{Número de divisões do conjunto de dados} \textit{Blocking}: 1, 2, 4, 8 divisões;
    \item \textbf{Passado Visível}: 60, 120, 240 e 480 minutos;
    \item \textbf{Tamanho do Intervalo Acumulado}: 150, 300, 450 segundos;
\end{itemize}

Para o número de divisões e passado visível é utilizado uma escala exponencial para ter uma noção de como essas variáveis afetam a medida que vão crescendo. Número de divisões tem seu máximo como 8, pois divisões muito maiores fariam com que o conjunto de treinamento tivesse menos de 1 semana. Passado visível tem seu máximo como 480 minutos por limitações de hardware. Já tamanho do intervalo acumulado é limitado a divisores de 15 minutos, visto que o trabalho tem como objetivo prever como o fluxo vai estar após 15, 30, 45 e 60 minutos. Além disso, tempos de acumulação inferiores tornam o dado muito ruidoso e tempo de acumulação superior torna o conjunto de dados muito pequeno.

A escolha de hiper-parâmetros será utilizada para verificar a sensibilidade dos modelos com os hiper-parâmetros antes escolhidos. Para essa fase, o conjunto de testes é divido em dois novamente (treino e teste \textit{tuning}). Isso é feito para evitar sobre-ajuste e os resultados finais sejam genéricos o suficiente para casos nunca visto antes. Para estes será feita uma busca total entre os parâmetros escolhidos, isto é, todos com todos. 

Para os modelos de aprendizagem profunda (\textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}}) os hiper-parâmetros são os mesmos. Segundo Greff et. al. \cite{Greff_2015}, que realizou extensos testes nesses dois modelos, chegou a conclusão que os dois fatores que mais afetam o aprendizado dos modelos são a taxa de aprendizado e o tamanho da rede. Sendo assim, esses dois foram escolhidos como os hiper-parâmetros, com as opções sendo:

\begin{itemize}
    \item \textbf{Taxa de Aprendizado}: 0.001, 0.004, 0.016 e 0.064;
    \item \textbf{Número de Células da Rede}: 50, 75, 100, 125 células;
\end{itemize}

A taxa de aprendizado tem uma escala exponencial sendo que o menor valor se baseia no valor padrão escolhido pelo biblioteca \textit{Keras}. Já o número de células da rede é limitada pelo hardware, visto que se tem um crescimento computacional significativo ao se aumentar o número de células. 

Para \textit{\acrshort{RF}} os hiper-parâmetros foram escolhidos para evitar o sobre-ajuste seguindo, em parte, a sugestão de Trevor Hastie et al. \cite{hastie2005elements} para construção de árvores e variando a quantidade de estimadores. Sendo assim, os hiper-parâmetros escolhidos foram a quantidade de estimadores (árvores) e altura máxima das árvores. A quantidade de estimadores e a altura máxima das árvores foram escolhido também um escala exponencial para ver como o modelo reage a medida que os valores crescem.  Sendo os valores escolhidos:

\begin{itemize}
    \item \textbf{Quantidade de Estimadores}: 50, 100, 200, 400, 800 estimadores;
    \item \textbf{Altura Máxima}: 8, 16, 32, 64 e sem limitações no tamanho;
\end{itemize}

% TODO: terminar SVM
Para \textit{\acrshort{SVM}} os hiper-parâmetros ...

\begin{itemize}
    \item \textbf{C}: 1, 10, 100 e 1000;
    \item \textbf{\(\gamma\)}: 4 valores espaçados, do espaço logarítmico de -2 a 2, e o padrão da biblioteca; 
\end{itemize}

\section{Avaliação Final}
% TODO: Justificar que não podemos usar MAPE como avaliação, pois nosso dataset inclui zeros (https://stats.stackexchange.com/questions/280464/is-mape-a-good-error-measurement-statistic-and-what-alternatives-are-there)

% TODO: worth a reading to complement the reason why we use normalised version (https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization)

% TODO: Explicar porque tem que ser utilizado janela deslizante em séries temporais, onde acho um artigo sobre isso?

% TODO: Falar das principais métricas usadas na literatura e colocar a referência.

Visto que os dados deste trabalho são séries temporais, realizou-se vários testes utilizando uma janela deslizante. Desta forma, foi possível testar os modelos sobre um conjunto de testes maior. Dessa forma, foi possível ter uma análise melhor de como os modelos se comportam com diferentes janelas de treinamento e teste. Todos os modelos serão treinados e testados com os mesmos subconjuntos de dados, para fins de comparação. Como métricas, fora utilizados \acrshort{MAE}, \acrshort{RMSE} e \acrshort{NRMSE}. 

\begin{equation}
MAE = \frac{1}{n} \times \sum_{i=1}^{n} \quad \abs{result_i - expected_i}
\end{equation}

\begin{equation}
RMSE = \sqrt{ \frac{1}{n} \times \sum_{i=1}^{n} \quad (result_i - expected_i) ^ 2}
\end{equation}

\begin{equation}
\sigma = \sqrt{ \frac{1}{n} \times \sum_{i=1}^{n} \quad (result_i - \overline{result}) ^ 2}
\end{equation}

\begin{equation}
NRMSE = \frac{RMSE(result, expected)}{\sigma(expected)}
\end{equation}

As duas primeiras métricas podem ser encontradas na literatura para avaliação dos modelos de predição de fluxo, a última é uma métrica utilizada para permitir comparações entre modelos que usam conjunto de dados diferentes, visto que ao ser normalizado ele perde a correlação com o conjunto de dados. Essas medições serão feitas para cada tempo de previsão discutido.

Além disso, será avaliado quanto a precisão (\(\alpha\)). No caso, será analisado com qual precisão o modelo consegue prever se o fluxo vai aumentar ou diminuir. Isto é:

\begin{equation}
f(x, y, z) =
\begin{cases}
  0, & \text{if}\ (x - z) \times (y - z) \textless 0 \\
  1, & \text{otherwise}
\end{cases}
\end{equation}

\begin{equation}
\alpha = \frac{\sum_{i=1}^{n} f(expected_i, result_i, k_i)}{n}
\end{equation}

Com \(k_i\) sendo o fluxo mais recente que o modelo possuiu como entrada quando ver a predição \(result_i\).

\section{Out Of Sample Testing}
%TODO: Adicionar imagem do Blocking
Para validar a performance de um modelo, é necessário fazer a utilização de métodos que comprovem a capacidade do mesmo de generalizar. Isto é, é preciso mostrar que o modelo é eficaz de maneira geral, ou para mais de um conjunto de dados. Uma das técnicas mais utilizadas é a \textit{Cross Validation}, que consiste em separar o conjunto de dados em conjuntos de dados menores para que se tenha mais blocos de dados para teste, treinamento e validação. Ao realizar esta divisão, utilizando-se \textit{Cross Validation}, a ordem dos dados não é necessariamente respeitada. Porém, o conjunto de dados deste trabalho é uma série temporal e a ordem dos registros importa, o que impossibilita a utilização deste método para este conjunto de dados. Entretanto, existem técnicas que se aplicam a predição de dados temporais. Tahsman em seu trabalho \cite{Tashman_2000} e Vitor et al em \cite{Vitor_2019} discorrem sobre esses métodos, chamados de \textit{Out of Sample Testing}, mostrando como são implementados estes tipos de validação e porque elas são adequadas para predição de séries temporais. Resumidamente, \textit{Out of Sample Testing} consiste em separar o conjunto de dados em conjunto de dados menores e independentes entre si, ou seja, dados que foram usados como treinamento em um conjunto, não serão utilizados como teste nos outros. Além de serem independentes, \textit{Out of Sample Testing} também respeita a ordem temporal dos dados, o que não afeta a correlação das informações com o tempo. Ainda em \cite{Tashman_2000}, são mostrados dois tipos de \textit{Out of Sample Testing}:

\begin{itemize}
    \item \textit{Fixed Origin}: Que consiste na definição de um, ou mais conjunto de dados derivados do conjunto de dados original, onde o ponto de divisão dos dados entre treinamento e teste é fixo.
    \item \textit{Rolling-origin}: Que consiste na definição de um, ou mais conjunto de dados derivados do conjunto de dados original, porém, neste caso, o ponto de divisão entre treinamento e teste é atualizado a cada iteração.
\end{itemize}

Neste trabalho, utilizou-se um método de \textit{Out Of Sample Testing} do tipo \textit{Rolling-Origin} chamado de \textit{Blocking}. Neste método, o conjunto de dados é dividido em subconjuntos de tamanhos iguais. Dentro de cada subconjunto, é definido o tamanho dos dados que serão utilizados para treinamento e teste.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{monography/img/methods/blocking_cv.png}
    \label{figure:blocking}
    \caption[Representação do \textit{Out-of-Sample Testing} realizado]{Representação do \textit{Out-of-Sample Testing} realizado}
\end{figure}