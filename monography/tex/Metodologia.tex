% TODO?: Usar a metodologia do Fábio como inspiração

% TODO: Incluir métricas de precisão

% TODO?: Falar sobre a especificação do ambiente

Este capítulo tem como objetivo explicar como foram realizadas as comparações dos modelos quanto as suas predições, assim como mostrado na Figura \ref{figure:metodologia}. Primeiramente será discutido os pré-processamentos dos dados, seguindo para os modelos, incluindo a razão por estes terem sido incluídos. Logo após será discutido como as otimizações foram feitas e como fora feita a avaliação dos modelos.


\begin{figure}
    \centering
    \includegraphics[scale=0.4]{monography/img/tccFlux.png}
    \label{figure:metodologia}
    \caption[Fluxograma da metodologia]{Fluxograma da metodologia}
\end{figure}

\section{Pré-Processamento dos Dados}
% TODO: Adicionar gráfico (fluxo por tempo) em tratamento de dados.

Nesta etapa serão feitas remoções de inconsistências e as transformações nos dados da Tabela \ref{table:data} para melhorar o aprendizado dos modelos. Além disso, como, a partir disso, foram criados os conjunto de dados de treinamento e teste.

\subsection{Limpeza dos Dados}

Nem todas as colunas são úteis para o aprendizado dos modelos, em especial, as colunas \texttt{Faixa}, \texttt{Hora}, \texttt{Limite de Velocidade da Via} e \texttt{Tamanho do Veículo}. \texttt{Faixa} será removido, pois nas transformações que virão a seguir esse dado se tornará desnecessário. \texttt{Hora} será removido, pois para ter algum efeito positivo no aprendizado dos modelos, seria preciso um estudo mais minucioso. \texttt{Limite de Velocidade da Via} será removido, pois este dado tem seu valor repetido ao longo de todos os registros, ou seja, é uma constante em todo o conjunto de dados. \texttt{Tamanho do Veículo} será removido, pois este não foi medido de forma precisa, visto que existem registros com veículos de tamanho nulo.

\subsection{Transformação dos Dados}

Caso fosse utilizado a coluna \texttt{Data} sem tratamento, ficaria a cargo dos modelos implementados extrair muitos dos significados por trás da mesma. Isto é, qual o dia da semana e o dia do mês referente àquela data, a qual a estação do ano aquele dia específico pertence. Então, para facilitar o aprendizado e evitar falsas suposições foi utilizado o método \textit{one-hot encoding} para transformar a coluna de \texttt{Data} em 7 colunas \textit{booleanas} que representam os dias da semana. Este tipo de tratamento se torna necessário devido ao fato de que o dia da semana é uma variável qualitativa e, caso fosse representada como quantitativa, (0 como domingo e 1 como segunda, por exemplo) o modelo poderia realizar inferências, como "segunda" é maior que "quarta", ou algo similar.

\subsection{Acumulação dos registros}

% TODO: mudar isso, ta errado
Como grande parte da literatura acerca da previsão de fluxo de veículos utiliza o fluxo para fazer o treinamento de suas redes neurais, também foi optado nesse trabalho por utilizá-lo. Além disso, como o domínio dos valores do nosso fluxo é menor que o domínio dos valores da densidade e da velocidade média, nossos modelos tendem a ter uma maior facilidade para realizar a previsão.

% TODO: Falar que aproveitamos e adicionamos no multivariado a densidade e a velocidade média
Sendo assim, será transformado o conjunto de dados de uma série temporal de registro de veículos para uma série temporal de fluxos. Isto é, será calculado a quantidade de veículos que passaram por um local em um determinado intervalo de tempo. Para definir o intervalo que utilizaríamos, testamos os valores de intervalo para 1, 2.5, 5 e 7.5 minutos. Isto, é usaremos minutos que sejam múltiplos de 15, visto que todos os tempos os quais vamos prever são múltiplos de 15.

No caso, os melhores resultados foram com a acumulação dos registros em um intervalo de 7.5 minutos. Isso se deve, em parte, ao fato de que quando se acumula os registros em um intervalo de tempo muito pequeno, o conjunto de dados apresenta muito ruído, dificultando a aprendizagem e afetando a qualidade da previsão. Em contrapartida, ao se aumentar o intervalo, o conjunto de dados pode se tornar muito pequeno, o que pode dificultar a aprendizagem. Tendo isso em mente, 7.5 minutos teve o melhor resultado, pois como nossa primeira previsão é para 15 minutos no futuro, não poderíamos utilizar um intervalo que não fosse divisor de 15, nem maior que 15. Ao final da transformação, temos um conjunto de dados similar ao mostrado na Tabela \ref{table:data_pre}. Abaixo também pode ser observado parte do código responsável por realizar esta transformação:

\begin{lstlisting}[language=Python, caption = GetFlow Python Function]
def get_flow (data, flow_interval, normalize, verbosity):
  date = np.asarray(data['Date'])
  weekDay = np.asarray(data['WeekDay'])
  time = np.asarray(data['Time'])
  speed = np.asarray(data['Speed'])
  
  dateControl = date[0]
  timeBlock = flow_interval
  countFlow = 0
  accSpeed = 0
  flowData = []

  for i in range(len(date)):
    if time[i] >= timeBlock: # init a new time block
      flowData.append(get_flow_data(countFlow, accSpeed, weekDay[i])) 
      timeBlock += flow_interval
      accSpeed = 0
      countFlow = 0
      
    if date[i] > dateControl: # reset on day change
      dateControl = date[i]
      timeBlock = flow_interval 
      countFlow = 0
      accSpeed = 0
      
    if time[i] < timeBlock: # add car on flow
      countFlow += 1
      accSpeed += speed[i]

  return flowData

\end{lstlisting}

\begin{table}[H]
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{1}{l}{\textbf{Flow}} & \multicolumn{1}{l}{\textbf{Density}} & \multicolumn{1}{l}{\textbf{Average Speed}} & \multicolumn{1}{l}{\textbf{Sun}} &
    \multicolumn{1}{l}{\textbf{Mon}} & \multicolumn{1}{l}{\textbf{Tue}} & \multicolumn{1}{l}{\textbf{Wed}} & \multicolumn{1}{l}{\textbf{Thu}} &
    \multicolumn{1}{l}{\textbf{Fri}} &
    \multicolumn{1}{l}{\textbf{Sat}} \\
    \midrule
     6 & 0.260870 & 23.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    17 & 0.586207 & 29.235294 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    15 & 0.625000 & 24.933333 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    18 & 0.666667 & 27.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    14 & 0.736842 & 19.500000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    14 & 0.700000 & 20.571429 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     6 & 0.352941 & 17.833333 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.400000 & 20.375000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    11 & 0.550000 & 20.181818 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    15 & 0.652174 & 23.466667 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    10 & 0.588235 & 17.700000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    13 & 0.722222 & 18.769231 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
    11 & 0.785714 & 14.363636 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.400000 & 20.125000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \midrule
     8 & 0.347826 & 23.750000 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
    \bottomrule
    \end{tabular}
    \label{table:data_pre}
    \caption{Amostra do pré-processamento dos dados ao se utilizar 7.5 minutos de intervalo do sensor RSI128}
\end{table}

No final do pré-processamento o resultado possuirá 3 colunas quantitativas e 7 qualitativas. As colunas de \textit{Density} e \textit{Average Speed} são contínuas e a coluna \textit{Flow} é discreto. As outras 7 colunas representam uma classificação indicando é ou não (0 representa falso e 1 verdadeiro) um certo dia da semana, sendo assim uma coluna qualitativa ordinal.

Vale notar que como o período é o mesmo para qualquer dos sensores, ao se acumular os registros, o tamanho do conjunto de dados será o mesmo. Isto é, será equivalente ao intervalo de tempo do conjunto de dados, 92 dias, divido pelo tempo de agregação, 7.5 minutos, o que gera 17.664 registros de fluxo.

\subsection{Sazonalidade dos dados}


Na Figura \ref{figure:flow_discution} é mostrado o resultado da agregação dos registros de veículos em um intervalo de 7.5 minutos. É possível observar que existem flutuações na quantidade de fluxo de veículo de acordo com o dia. Este fato fica mais evidente se observarmos o primeiro pico do gráfico, referente ao Domingo, pois este apresenta um menor fluxo de veículos, o que é esperado que aconteça em um dia não comercial. Isso mostra que os dados apresentam certa sazonalidade. Esta sazonalidade se manifesta em várias escalas, no gráfico mostrado é possível ver apenas a sazonalidade referente aos dias da semana, mas ela também se aplica, por exemplo, a semana do mês, ao mês do ano, etc. Por este motivo, o escopo deste trabalho foi definido apenas para os 3 meses de dados disponíveis. 


\begin{figure}
    \centering
    \includegraphics[scale=1]{monography/img/flows/flow_450_week_01.png}
    \label{figure:flow_discution}
    \caption[Fluxo da Primeira Semana]{Fluxo da Primeira Semana}
\end{figure}

\subsection{Normalização dos Dados}
% TODO: adicionar referência do porque normalizar dados
Na área de aprendizagem de máquina, é comum vermos modelos de predições para diferentes tipo de variáveis. Por vezes, os valores assumidos por essas variáveis podem apresentar um domínio grande demais, como no caso da predição de valores de ações da bolsa de valores. Com valores em um intervalo tão grande, o treinamento dos modelos tende a piorar. Para contornar este problema, é comum utilizar técnicas que visam diminuir o intervalo de valores que as variáveis podem assumir. Uma destas técnicas é a normalização. Em um dos tipos da normalização, utiliza-se o maior e o menor valor que o seu conjunto de dados atinge para ajustar os valores intermediários. O maior fluxo calculado foi 94 para o sensor \textbf{RSI128} e o menor foi 0. Assim, ajustamos os valores do conjunto de dados dentro de um intervalo entre 0 e 1, com 0 representando o menor valor e 60, o maior valor. 

Além disso, em função do modo de como alguns dos modelos funcionam, como o \textit{\acrshort{LSTM}}, serão utilizados as versões normalizados dos conjuntos de dados para tornar mais efetivo o treinamento dos mesmos. Vale notar que ao normalizar, a coluna de \texttt{Flow} se tornou quantitativa contínua.

\begin{table}[htbp]
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{1}{l}{\textbf{Flow}} & \multicolumn{1}{l}{\textbf{Density}} & \multicolumn{1}{l}{\textbf{Average Speed}} & \multicolumn{1}{l}{\textbf{Sun}} &
    \multicolumn{1}{l}{\textbf{Mon}} & \multicolumn{1}{l}{\textbf{Tue}} & \multicolumn{1}{l}{\textbf{Wed}} & \multicolumn{1}{l}{\textbf{Thu}} &
    \multicolumn{1}{l}{\textbf{Fri}} &
    \multicolumn{1}{l}{\textbf{Sat}} \\
    \midrule
    0.063830 & 0.081838 & 0.412281 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.180851 & 0.186387 & 0.512900 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.159574 & 0.192835 & 0.437427 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.191489 & 0.209804 & 0.482456 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.148936 & 0.230127 & 0.342105 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.148936 & 0.218141 & 0.360902 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.063830 & 0.107843 & 0.312865 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.085106 & 0.125854 & 0.357456 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.117021 & 0.174705 & 0.354067 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.159574 & 0.204887 & 0.411696 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.106383 & 0.181093 & 0.310526 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.138298 & 0.222009 & 0.329285 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.117021 & 0.245472 & 0.251994 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.085106 & 0.127417 & 0.353070 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \midrule
    0.085106 & 0.107969 & 0.416667 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.0 
    \\
    \bottomrule
    \end{tabular}
    \label{table:data_pre_norm}
    \caption{Amostra do pré-processamento normalizado dos dados ao se utilizar 7.5 minutos de intervalo do sensor \textbf{RSI128}}
\end{table}

Importante notar que nessa transformação existe uma diminuição significativa do conjunto de dados. Por exemplo, o sensor \textbf{RSI128} que possuía 536.879 registros de passagem de veículos passou a ter 17.664 registros de fluxo.


\subsection{Produção dos Conjunto de Dados}

Será utilizado o conjunto de dados pré-processados para gerar o conjunto de dados de treino e teste. Cada elemento do conjunto de treino será série temporal de atributos. Ou seja, cada elemento de treino terá \(n\) instâncias do passado, cada instância será uma das linhas da Tabela \ref{table:data_pre_norm}. Para o conjunto de testes, cada elemento será o fluxo corresponde no futuro.

% TODO: adicionar imagem ou formulas matemáticas para melhorar o entendimento

Para se adaptar aos modelos, serão gerados duas versões do conjunto de dados de treino e teste. Uma versão será para os modelos tradicionais (\textit{\acrshort{RF}} e \textit{\acrshort{SVM}}), que terá somente duas dimensões (amostras por atributos) e a outra para os modelos de aprendizagem profunda (\textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}}) com três dimensões (amostras por passos por atributos).

Para fins de análise, utiliza-se o conjunto de dados de treino para gerar um outro conjunto de dados de treino mais simples. Este conjunto mais simples possuirá somente o fluxo, permitindo assim verificar se as colunas de \texttt{VelocidadeMédia}, \texttt{Density} e as de dias da semana melhoram a performance do modelo. Deste modo, tem-se um conjunto de dados uni-variado, isto é, possuirá somente um tipo de variável, o fluxo. E o outro será multi-variado, isto é, possuirá vários tipos de variáveis, sendo elas o fluxo, a velocidade média no intervalo e o dia da semana.

\section{Modelos}

Visto que a predição do fluxo é o foco do trabalho e que que o fluxo é quantitativo, serão utilizados modelos de regressão para encontrar um padrão nos dados. Ou seja, serão utilizados modelos guiados por dados. Segundo o artigo \textit{Short-Term Travel-Time Prediction on Highway: A Review of the Data-Driven Approach} por Simon Oh et. al. \cite{doi:10.1080/01441647.2014.992496}, estes modelos podem ser classificados em dois grupos: paramétricos e não-paramétricos. Modelos paramétricos usam um número fixo de parâmetros para tentar descrever os dados, assumindo assim que os dados seguem uma distribuição específica. Um exemplo de modelo paramétrico seria a regressão linear, que utiliza uma equação com parâmetros fixos para traçar uma reta que melhor representa a distribuição dos dados. Já modelos não-paramétricos possuem um número variável de parâmetros que dependem dos dados utilizados. Assim, não assumindo uma distribuição específica nos dados.

% TODO: Adicionar referencia para mostrar que o ARIMA é um dos mais utilizados
Dos modelos paramétricos, o mais utilizado na literatura para previsão de fluxo é o \textit{\acrfull{ARIMA}} e suas variações, além de modelos mais simples como \textit{\acrfull{LR}}. Dos modelos não-paramétricos, se destacam o \textit{\acrfull{LSTM}} e o \textit{\acrfull{GRU}}, sendo ambos \textit{\acrshort{RNN}}'s.

% TODO: falar que estamos utilizando um modelo para cada tipo de viés (rf para arvores, etc)

Todos os modelos não-paramétricos citados foram implementados para este trabalho. Quanto aos modelos paramétricos, foram testados dois modelos, sendo eles o \textit{\acrshort{ARIMA}} e o \textit{\acrshort{LR}}. Porém, ambos tiveram resultados inferiores em relação aos modelos não-paramétricos testados, sendo que ambos estavam utilizando os parâmetros padrões da biblioteca \textit{StatModels}. Além disso, \textit{\acrshort{ARIMA}} se mostrou extremamente custosos computacionalmente de se treinar e otimizar. Por estes dois motivos citados, os modelos paramétricos foram retirados dos experimentos.

%TODO: EXPLICAR NAIVE
\subsection{Modelos de Comparação}

Serão utilizados também dois modelos com o único propósito de estabelecer uma base de comparação inicial para os outros modelos. Serão eles o \textit{Naive} e \textit{Moving Average}. O primeiro faz suas predições apenas escolhendo o valor de fluxo mais recente dos que recebeu de entrada. Já o segundo faz a média dos valores de fluxo recebidos na entrada. Dessa forma, é possível colocar em perspectiva o desempenho dos modelos escolhidos. Também fora implementado o \textit{Random Guess} cujo respondia aleatoriamente para qualquer entrada (valores entre o menor e maior elemento encontrado no conjunto), porém este era muito inferior e decidimos retirá-lo.

\subsection{Implementação}

As arquiteturas utilizadas neste trabalho foram implementados na linguagem \textit{Python} utilizando bibliotecas como \textit{Keras} com \textit{TensorFlow} e \textit{SKLearn}. Decidiu-se por utilizar essas bibliotecas, pois suas implementações já são robustas, otimizadas e bem testadas. Implementar todos os modelos sem o auxílio de nenhuma biblioteca seria ineficiente para objetivo dos experimentos e prono a erros. Além disso, o uso das bibliotecas facilita a reprodução dos experimentos para os interessados em avançar ou verificar este projeto.

\textit{Keras} foi utilizado para implementar os modelos de \textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}} e optou-se por usar como base dessa biblioteca o \textit{TensorFlow}, visto que este é o \textit{framework} com suporte para aprendizado de máquina mais utilizado dentre os desenvolvedores, segundo um questionário feito em 2018 pelo \textit{Stack Overflow} \cite{stack_2018}. Já \textit{SKLearn} foi utilizado para implementar os modelos \acrshort{RF} e \acrshort{SVM}. Além disso, utilizou-se a biblioteca \textit {SKLearn} para realizar uma pesquisa dos melhores parâmetros e hiper-parâmetros.

\section{Escolha de Parâmetros e Hiper-Parâmetros}

Para a escolha dos parâmetros e hiper-parâmetros será feito uma busca total dos melhores para cada modelo. Para os modelos de aprendizagem profunda (\textit{\acrshort{LSTM}} e \textit{\acrshort{GRU}}) será feita a pesquisa nos seguintes hiper-parâmetros.

% TODO: Explicar para que serve cada parametro

\begin{itemize}
    \item \textbf{Tamanho do \textit{Batch}:} 16, 32 e 64; \newline
    O tamanho do batch serve para...
    \item \textbf{Otimizador do Modelo:} Adam; \newline
    O otimizador do modelo serve para...
    \item \textbf{Quantidade de Células:} 20, 30, 40; \newline
    A quantidade de células serve para...
\end{itemize}

Para a \textit{\acrshort{SVM}} foram escolhidos os hiper-parâmetros:

\begin{itemize}
    \item \textbf{Gamma:} Scale;
    \item \textbf{C:} [1, 25, 50, 75, 100];
    \item \textbf{Kernel:} RBF e Linear;
\end{itemize}

Já os parâmetros escolhidos para \textit{\acrshort{RF}} foram:

\begin{itemize}
    \item \textbf{\textit{Bootstrap}:} Ativado e Desativado;
    O bootstrap serve para...
    \item \textbf{Número de Estimadores:} 75, 100, 125, 150 e 175;
    O número de estimadores ajuda a tornar mais preciso os resultados, uma vez que aumenta a probabilidade de terem mais árvores que acharam melhor padrão.
    \item \textbf{Altura Máxima da Árvore:} 30, 40, 50, 60, 70 e a padrão;
    Limitar a altura máxima das árvores de decisão auxilia a evitar o sobre-ajuste, pois torna mais difícil da árvore "decorar" as respostas das entradas.
    
    
\end{itemize}

\section{Avaliação Final}
% TODO: Justificar que não podemos usar MAPE como avaliação, pois nosso dataset inclui zeros (https://stats.stackexchange.com/questions/280464/is-mape-a-good-error-measurement-statistic-and-what-alternatives-are-there)

% TODO: worth a reading to complement the reason why we use normalised version (https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization)

% TODO: Explicar porque tem que ser utilizado janela deslizante em séries temporais, onde acho um artigo sobre isso?

% TODO: Falar das principais métricas usadas na literatura e colocar a referência.

Visto que os dados deste trabalho são séries temporais, realizou-se vários testes utilizando uma janela deslizante. Desta forma, foi possível testar os modelos sobre um conjunto de testes maior. Dessa forma, foi possível ter uma análise melhor de como os modelos se comportam com diferentes janelas de treinamento e teste. Todos os modelos serão treinados e testados com os mesmos subconjuntos de dados, para fins de comparação. Como métricas, fora utilizados \acrshort{MAE}, \acrshort{RMSE} e \acrshort{NRMSE}. 

\begin{equation}
MAE = \frac{1}{n} \times \sum_{i=1}^{n} \quad \abs{result_i - expected_i}
\end{equation}

\begin{equation}
RMSE = \sqrt{ \frac{1}{n} \times \sum_{i=1}^{n} \quad (result_i - expected_i) ^ 2}
\end{equation}

\begin{equation}
\sigma = \sqrt{ \frac{1}{n} \times \sum_{i=1}^{n} \quad (result_i - \overline{result}) ^ 2}
\end{equation}

\begin{equation}
NRMSE = \frac{RMSE(result, expected)}{\sigma(expected)}
\end{equation}

As duas primeiras métricas podem ser encontradas na literatura para avaliação dos modelos de predição de fluxo, a última é uma métrica utilizada para permitir comparações entre modelos que usam conjunto de dados diferentes, visto que ao ser normalizado ele perde a correlação com o conjunto de dados. Essas medições serão feitas para cada tempo de previsão discutido.

Além disso, será avaliado quanto a precisão (\(\alpha\)). No caso, será analisado com qual precisão o modelo consegue prever se o fluxo vai aumentar ou diminuir. Isto é:

\begin{equation}
f(x, y, z) =
\begin{cases}
  0, & \text{if}\ (x - z) \times (y - z) \textless 0 \\
  1, & \text{otherwise}
\end{cases}
\end{equation}

\begin{equation}
\alpha = \frac{\sum_{i=1}^{n} f(expected_i, result_i, k_i)}{n}
\end{equation}

Com \(k_i\) sendo o fluxo mais recente que o modelo possuiu como entrada quando ver a predição \(result_i\).