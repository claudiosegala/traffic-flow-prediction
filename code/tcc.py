# -*- coding: utf-8 -*-
"""tcc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fpyYtJyD0OtH2pP_DKB9QpaTzfUICiMu

# TCC

# Mount Drive

Connect to Google Drive of 'alfredcoinworth'
"""

import google as g # To connect with google drive
g.colab.drive.mount('/content/drive')

"""# Retrieve and Instanciate Dependencies

For this work, we will need these libraries
"""

!pip install tensorflow
!pip install pandas
!pip install matplotlib
!pip install numpy
!pip install sklearn
!pip install keras
!pip install statsmodels

import tensorflow as tf # machine learning library
import pandas as pd # data manipulation library
import matplotlib.pyplot as plt # plot library
import numpy as np # math library
import datetime as dt # to discover week day
import time as tm # to convert to seconds
import sklearn as skl # regression templates library
import sklearn.metrics as sklm # metrics
import statsmodels.api as sma # statistical models api
import statistics as st # statistics
import statsmodels as sm # statistical models

import math
import json
import copy

from sklearn.preprocessing import MinMaxScaler

from keras.models import Sequential
from keras.layers import Dense, Activation

"""# Configurations"""

tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

PATH = '/content/drive/My Drive/TCC/' # ''

VERBOSITY = True

SHOW_PLOT = True

"""# General Util"""

def flatten (m):
  """ Flatten
  
  Transform a matrix in an array.
  
  Arguments:
    m: the matrix to be flatten
  """
  
  return [i for sl in m for i in sl]

"""# Dataset Retrieval Util

This phase we have to get the data stored in Google Drive and transform into a dataset for prediction.
"""

def retrieve_data(verbosity):
  path = f"{PATH}dataset/all_data_sorted.csv"
  
  col_names = [
    'Sensor',
    'Date',
    'Time',
    'Lane',
    'Speed',
    'Max Speed',
    'Size'
  ]
  
  data = pd.read_csv(path, ';', header=None, names=col_names)
  
  if verbosity:
    print(f"It contains {len(data['Sensor'])} entries\n\n")
    print(data.head(), end="\n\n")
    print(data.describe(), end="\n\n")
    
  return data

def clean_data(data, verbosity):
  if verbosity:
    print(f"This dataset contains {len(set(data['Sensor']))} sensors.")
    print(f"We will be using only one.")
  
  # Extract data from just one sensor
  data = data[data['Sensor'] == 'RSI128']
  
  # Remove unnecessary columns
  data = data.drop(columns=['Sensor','Lane','Max Speed','Size'])
  
  data['Date'] = pd.to_datetime(data['Date'], format='%Y/%m/%d')
   
  # Adjust type
  f = lambda x : tm.strptime(x, '%H:%M:%S')
  data['Time'] = data['Time'].apply(f)
  
  g = lambda x : dt.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()
  data['Time'] = data['Time'].apply(g)
  
  h = lambda x : int(x)
  data['Time'] = data['Time'].apply(h)
  
  i = lambda x : float(x)
  data['Speed'].apply(i)
  
  # Create week day from date
  j = lambda x : x.weekday()
  data['WeekDay'] = data['Date'].apply(j)
  
  if verbosity:
    for col, cont in data.iteritems():
        print(f"Column {col} has {cont.isnull().sum()} null elements")
        print(f"Column {col} has {cont.isna().sum()} nan elements")
        
    print()
        
    start = data['Date'].min()
    end = data['Date'].max()
    print(f"This data is from <{start}> to <{end}>. {end - start} days.\n")

    print(f"It contains {len(data['Date'])} entries\n\n")

    print(data.head(), end="\n\n")
    print(data.describe(), end="\n\n")
  
  return data

"""# Flow Generation Util

The plot is based on [A Guide to Time Series Visualization with Python 3](https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-visualization-with-python-3).
"""

def get_flow_data(n, accSpeed, weekDay):
  avgSpeed = (accSpeed // n) if n else 0
  density = (n / avgSpeed) if avgSpeed else 0
  w = [(1 if weekDay == i else 0) for i in range(7)] # weekday
  
  return (n, density, avgSpeed, w[0], w[1], w[2], w[3], w[4], w[5], w[6])

def plot_flow(flow_series, freq):
  path = f"{PATH}plots/seasonal_decompose"
  
  decompose = sm.tsa.seasonal.seasonal_decompose
  decomposition = decompose(flow_series, model='additive', freq=freq)
  fig = decomposition.plot()

  plt.rcdefaults()
#   plt.plot()
  
  plt.savefig(path + ".png")
  plt.savefig(path + ".pdf")
  
  if SHOW_PLOT:
    plt.show()
    
  plt.close('all')

def get_flow (data, flow_interval, normalize, verbosity):
  date = np.asarray(data['Date'])
  weekDay = np.asarray(data['WeekDay'])
  time = np.asarray(data['Time'])
  speed = np.asarray(data['Speed'])
  
  dateControl = date[0]
  timeBlock = flow_interval
  countFlow = 0
  accSpeed = 0
  flowData = []

  for i in range(len(date)):
    if time[i] >= timeBlock: # init a new time block
      flowData.append(get_flow_data(countFlow, accSpeed, weekDay[i])) 
      timeBlock += flow_interval
      accSpeed = 0
      countFlow = 0
      
    if date[i] > dateControl: # reset on day change
      dateControl = date[i]
      timeBlock = flow_interval 
      countFlow = 0
      accSpeed = 0
      
    if time[i] < timeBlock: # add car on flow
      countFlow += 1
      accSpeed += speed[i]
      
  flowDataColumns = [
    'Flow',
    'Density',
    'AveSpeed',
    'Sunday',
    'Monday',
    'Tuesday',
    'Wednesday',
    'Thursday',
    'Friday',
    'Saturday'
  ]
  
  flowData = pd.DataFrame(flowData, columns=flowDataColumns)
  
  if normalize:
    scaler = skl.preprocessing.MinMaxScaler(feature_range=(0,1))
    flowDataScaled = scaler.fit_transform(flowData)  
    flowData = pd.DataFrame(flowDataScaled, columns=flowData.columns, index=flowData.index)
  

  if verbosity:
    plot_flow(flowData['Flow'], WEEK_SIZE)

    flowData.describe()
  
  return flowData

"""# Dataset Generation Util"""

# 
def split_sequence(sequence, isMulti, n_steps, n_future):
  """ Split Sequence
  
  Split a sequence in rolling intervals with a corresponding value 
  like the example bellow.
  
  Ex: split_sequence([1, 2, 3, 4, 5], 3) #([[1, 2, 3], [2, 3, 4]], [4, 5])
  
  Arguments:
    sequence: the sequence to split.
    isMulti: if the data is multivariate or not.
    n_steps: size of the rolling interval
    n_future: the distance to the interval the value should be.  
  """
  
  n = len(sequence)
  X, Y = list(), list()
  
  for i in range(n):
    j = i + n_steps
    k = j + n_future

    if k >= n:
      break

    seq_x, seq_y = sequence[i:j], sequence[k]
    X.append(seq_x)
    Y.append(seq_y[0] if isMulti else seq_y)

  return np.array(X), np.array(Y)

def reshape_flow (raw_seq, isMulti, n_steps, n_future, verbosity): 
  """ Reshape Flow
  
  Reshape a sequence in rolling intervals from [samples, timesteps] into 
  [samples, timesteps, features].
  
  Arguments:
    raw_seq: the sequence to reshape.
    isMulti: if the data is multivariate or not.
    n_steps: size of the rolling interval
    n_future: the distance to the interval the value should be.  
  """
  
  X, Y = split_sequence(np.array(raw_seq), isMulti, n_steps, n_future)
  
  
  if not isMulti:
    X = X.reshape((X.shape[0], X.shape[1], 1))
    
  if verbosity:
    print(f"X Shape: {X.shape}")
    print(f"Y Shape: {Y.shape}")

  return X, Y

"""# Models Util

## Misc

Function to help implement the training and evaluation of the models.
"""

def plot_history (history, name):
  """ Plot of History
  
  Plot the history of loss in the training session of a model
  
  Arguments:
    history: the history returned by Keras fit of a model
    name: the name of the model
  """
  
  path = f"{PATH}plots/histories/{name}"
  
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title(name + ' Model Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['train', 'test'], loc='upper left')
  plt.rcdefaults()
  
  plt.savefig(path + ".png", bbox_inches='tight')
  plt.savefig(path + ".pdf")
  
  #plt.show(name + "ind")
  plt.close('all')

def plot_prediction (Y, Y_hat, title):
  """ Plot Prediction
  
  Plot the prediction (Flow x Time) of what was expected and what
  was predicted.
  
  """
  
  
  Y = flatten(Y)
  Y_hat = flatten(Y_hat)
  n = math.floor(len(Y) / DAY_SIZE)
  
  for r in range(n):
    i = r * DAY_SIZE
    j = min(i + DAY_SIZE, len(Y))
    
    name = f"{title} ({str(r+1).zfill(2)} of {n})"
    path = f"{PATH}plots/predictions/{name}"
    
    plt.plot(Y[i:j])
    plt.plot(Y_hat[i:j])
    plt.title(title + 'Prediction')
    plt.ylabel('Flow')
    plt.xlabel('Time')
    plt.legend(['actual', 'prediction'], loc='upper left')
    plt.rcdefaults()

    plt.savefig(path + ".png", bbox_inches='tight')
    plt.savefig(path + ".pdf")

    plt.close('all')

def split_dataset (n, window_split, test_split):
  """ Dataset Split
  
  Generate pointers for the training and test of the models based
  on the splits.
  
  Arguments:
    n: size of the dataset.
    window_split: percentage of the dataset that will be used in each 
      train&test sample.
    test_split: percentage of the train&test sample that will be 
      dedicated to testing.
  """
  
  sz_window = int(n * window_split)
  sz_test = int(sz_window * test_split)
  sz_train = sz_window - sz_test
  sz_jump = sz_test

  i, j, k = 0, sz_train, min(n, sz_train + sz_test)
  
  res = []
  
  while j < n:
    res.append((i, j, k))
    
    i = i + sz_jump
    j = i + sz_train
    k = min(n, j + sz_test)
    
  return res

def evaluate_precision_hit_ratio (Y, Y_hat):
  """ Trend Prediction Ratio Calculation
  
  Calculates the ratio of up/down prediction.
  
  Arguments:
    Y: the expected dataset.
    Y_hat: the observed dataset.
  """
  
  cnt = 0
  
  for i in range(len(Y)):
    if i < N_FUTURE:
      continue
      
    exp = Y[i] - Y[i - N_FUTURE]
    obs = Y_hat[i] - Y[i - N_FUTURE]
    
    if exp * obs > 0:
      cnt += 1
    
  return cnt / len(Y)

def evaluate_precision_bucket (Y, Y_hat):
  """ Precision Bucket Calculation
  
  Counts how many of the prediction got wronng by at most 2Ë†x, x 
  being the bucket. There are 7 buckets, that is, the maximum error 
  calculated is 128.
  
  Arguments:
    Y: the expected dataset.
    Y_hat: the observed dataset.
  """
  
  n = 7 # the number of buckets
  buckets = [0] * n
  
  for i in range(len(Y)):
    diff = abs(Y[i] - Y_hat[i])
    
    for i in range (n):
      if diff <= 2**i:
        buckets[i] += 1
        break

  for i in range (n):
     buckets[i] = buckets[i] / len(Y)

  return tuple(buckets)

def evaluate_raw (expected, observed, times):
  """ Evaluate Raw Sessions 
  
  Evaluate each of the train&test sessions by RMSE, NRMSE, MAE, HR, PRE. 
  It will store the results in a object and return it.
  
  Arguments:
    expected: an array of expected instances of each train&test session.
    observed: an array of observed instances of each train&test session.
    times: an array of the time of each train&test session.
  """
  
  n = len(expected)
  
  raw = {
    'expected': expected,
    'observed': observed,
    'TIME': times,
    'RMSE': [0] * n,
    'NRMSE': [0] * n,
    'MAE': [0] * n,
    'HR': [0] * n,
    #'PRE': [0] * n,
  }
  
  for i in range(n):
    Y = expected[i]
    Y_hat = observed[i]
    time = times[i]

    raw['MAE'][i] = sklm.mean_absolute_error(Y, Y_hat)
    raw['RMSE'][i] = np.sqrt(sklm.mean_squared_error(Y, Y_hat))
    raw['NRMSE'][i] = raw['RMSE'][i] / np.std(Y)
    raw['HR'][i] = evaluate_precision_hit_ratio(Y, Y_hat)
    #raw['PRE'][i] = evaluate_precision_bucket(Y, Y_hat)
    
    if VERBOSITY:
      print(f"({i+1}/{n}) Test Size: {len(Y)}, Time: {time}s")
      print(f"\tRMSE: {raw['RMSE'][i]}")
      print(f"\tNRMSE: {raw['NRMSE'][i]}")
      print(f"\tMAE: {raw['MAE'][i]}")
      print(f"\tHit Ratio: {raw['HR'][i] * 100}%")

  return raw

def evaluate (expected, observed, times, name):
  """ Evaluate Sessions
  
  Evaluate models by RMSE, NRMSE, MAE, HR, PRE. It will store the 
  results in a object and return it.
  
  Arguments:
    expected: an array of expected instances of each 
      train&test session.
    observed: an array of observed instances of each 
      train&test session.
    times: an array of the time of each train&test session.
    desnormalize: if it should desnormalize the results
  """
  n = len(expected)
  
  # Make the arrays serializable
  expected = list(map(list, expected))
  observed = list(map(list, observed))
  
  for i in range(n):
    expected[i] = list(map(float, expected[i]))
    observed[i] = list(map(float, observed[i]))
  
  raw = evaluate_raw(expected, observed, times)
  
  #n_buckets = len(raw['PRE'])
  #_pre = [[pre[i] for pre in raw['PRE']] for i in range(n_buckets)]
  
  eva = {
    'TIME': int(sum(times)),
    'RMSE': float(np.mean(raw['RMSE'])),
    'NRMSE': float(np.mean(raw['NRMSE'])),
    'MAE': float(np.mean(raw['MAE'])),
    'HR': float(np.mean(raw['HR'])),
    #'PRE': [float(np.mean(p)) for p in _pre],
    'has_negative': (min(flatten(observed)) < 0),
    'raw': raw
  }
  
  print(f"\n{name} Final Result:")
  print(f"\tTotal Time: {eva['TIME']}s")
  print(f"\tRMSE: {eva['RMSE']}")
  print(f"\tNRMSE: {eva['NRMSE']}")
  print(f"\tMAE: {eva['MAE']}")
  print(f"\tHit Ratio: {eva['HR'] * 100}%")
  #print(f"\tPrecision: {eva['PRE']}")
    
  return eva

def generate_dataset(data, isMulti, flow_interval, n_step, n_future, normalize, verbosity):
  multivariateData = get_flow(data, flow_interval, normalize, False)
  univariateData = multivariateData['Flow']
  
  return reshape_flow(
      multivariateData if isMulti else univariateData, 
      isMulti, 
      n_step, 
      n_future, 
      False
  )

"""## Random (Baseline)

This implementation just guess a random number in the [0, 100] interval for every output.
"""

import random as rnd # random

def random_guess_univariate (data):
  global result_data
  
  X, Y = generate_dataset(data, False, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)

  name = "Random Guess"
  m = max(Y)

  expected, observed, times = [], [], []
  pointers = split_dataset(len(Y), SET_SPLIT, TEST_SPLIT)
  
  for i, j, k in pointers:
    start = tm.time()

    Y_hat = [rnd.randint(0, m) for i in range(k - j)]

    expected.append(Y[j:k])
    observed.append(Y_hat)
    times.append(tm.time() - start)

  result_data['results'][name] = evaluate(expected, observed, times, name)

  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## Moving Average (Baseline)

This implementation just get the mean of every flow value in the input and place it as output.
"""

def moving_average (data):
  global result_data
  
  X, Y = generate_dataset(data, False, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  
  name = "Moving Average"
  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  X = X.reshape(X.shape[0], X.shape[1])
  
  for i, j, k in pointers:
    start = tm.time()
    
    Y_hat = [np.mean(x) for x in X[j:k]]
    
    expected.append(Y[j:k])
    observed.append(Y_hat)
    times.append(tm.time() - start)
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## Naive (Baseline)

This implementation just use the last value of input as output.
"""

def naive (data):
  global result_data
  
  X, Y = generate_dataset(data, False, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  
  name = "Naive"
  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  X = X.reshape(X.shape[0], X.shape[1])
  
  for i, j, k in pointers:
    start = tm.time()
    
    Y_hat = [x[-1] for x in X[j:k]]
    
    expected.append(Y[j:k])
    observed.append(Y_hat)
    times.append(tm.time() - start)
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression

def logistic_regression(data, isMulti):
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  
  name = "LR Multivariate" if isMulti else "LR Univariate"
  
  model = LogisticRegression()

  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])
  
  for i, j, k in pointers:
    start = tm.time()
    
    model.fit(X[i:j], Y[i:j])
    
    expected.append(Y[j:k])
    observed.append(model.predict(X[j:k]))
    times.append(tm.time() - start)
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## Random Forest

This implementation is based on [Random Forest Algorithm with Python and Scikit-Learn](https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/)
"""

from sklearn.ensemble import RandomForestRegressor

def random_forest_grid(data, isMulti):
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])
  
  name = "RF Multivariate" if isMulti else "RF Univariate"
  
  cv=[(slice(None), slice(None))] # to ignore the cross-validation
  param_grid = {
    'bootstrap': [True, False],
    'max_depth': [30, 40, 50, 60, 70, None],
    'max_features': [1, 3, 5, 7, 9],
#     'min_samples_leaf': [5, 10, 15],
#     'min_samples_split': [5, 10, 15],
    'n_estimators': [100, 125, 150, 175, 200, 225]
  }
  
  model = skl.ensemble.RandomForestRegressor(random_state=0)
  
  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, verbose=2)
  
  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)

  gs.fit(X[i:j], Y[i:j])
  print(gs.best_params_)
  
  
  best = gs.best_estimator_
  predictions = best.predict(X[j:k])                         
      
  mae = sklm.mean_absolute_error(Y[j:k], predictions)
  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))
  nrmse = rmse / np.std(Y[j:k])
  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)
  
  print(f"MAE = {mae}")
  print(f"RMSE = {rmse}")
  print(f"NRMSE = {nrmse}")
  print(f"HR = {hr}")

def random_forest(data, isMulti):
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])
  
  name = "RF Multivariate" if isMulti else "RF Univariate"
  
  model = skl.ensemble.RandomForestRegressor(n_estimators=100, max_features='auto', random_state=0)

  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  for i, j, k in pointers:
    start = tm.time()
    
    model.fit(X[i:j], Y[i:j])
    
    expected.append(Y[j:k])
    observed.append(model.predict(X[j:k]))
    times.append(tm.time() - start)
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## Support Vector Machine"""

from sklearn import svm

def support_vector_machine_grid(data, isMulti):
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])
  
  name = "SVM Multivariate" if isMulti else "SVM Univariate"
  
  cv=[(slice(None), slice(None))]
  param_grid = {
    'C': [1, 25, 50, 75, 100],
    'gamma': np.logspace(-2, 2),
    'kernel': ['rbf', 'linear']
  }
  
  model = svm.SVR()
  
  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, verbose=2)
  
  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)

  gs.fit(X[i:j], Y[i:j])
  print(gs.best_params_)
  
  best = gs.best_estimator_
  predictions = best.predict(X[j:k])                         
      
  mae = sklm.mean_absolute_error(Y[j:k], predictions)
  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))
  nrmse = rmse / np.std(Y[j:k])
  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)
  
  print(f"MAE = {mae}")
  print(f"RMSE = {rmse}")
  print(f"NRMSE = {nrmse}")
  print(f"HR = {hr}")

def support_vector_machine(data, isMulti):
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])
  
  name = "SVM Multivariate" if isMulti else "SVM Univariate"
  
  model = svm.SVR(gamma='scale', C=1.0, epsilon=0.2)

  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  for i, j, k in pointers:
    start = tm.time()
    
    model.fit(X[i:j], Y[i:j])
    
    expected.append(Y[j:k])
    observed.append(model.predict(X[j:k]))
    times.append(tm.time() - start)
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## RNN"""

from keras.layers import SimpleRNN

def create_rnn(input_shape):
  model = Sequential()
  
  model.add(SimpleRNN(50, activation='relu', input_shape=input_shape))
  model.add(Dense(1, activation='sigmoid' if NORMALIZE else 'relu'))
  
  model.compile(optimizer='adam', loss='mse', metrics = ["accuracy"])
  
  return model

def rnn (data, isMulti): 
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  
  name = "RNN Multivariate" if isMulti else "RNN Univariate"
  
  model = create_rnn((X.shape[1], X.shape[2]))
  
  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  for i, j, k in pointers:
    start = tm.time()
    
    hist = model.fit(X[i:j], Y[i:j], validation_split=0.2, batch_size=64, epochs=15, verbose=0)
    
    expected.append(Y[j:k])
    observed.append(model.predict(X[j:k]))
    times.append(tm.time() - start)
    
    if VERBOSITY:
      plot_history(hist, f"{name} ({str(len(times)).zfill(2)} of {len(pointers)})")
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## LSTM"""

from keras.layers import LSTM

def create_lstm(input_shape):
  model = Sequential()
  
  model.add(LSTM(50, activation='relu', input_shape=input_shape))
  model.add(Dense(1, activation='sigmoid' if NORMALIZE else 'relu'))
  
  model.compile(optimizer='adam', loss='mse', metrics = ["accuracy"])
  
  return model

def lstm (data, isMulti): 
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  
  name = "LSTM Multivariate" if isMulti else "LSTM Univariate"
  
  model = create_lstm((X.shape[1], X.shape[2]))
  
  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  for i, j, k in pointers:
    start = tm.time()
    
    hist = model.fit(X[i:j], Y[i:j], validation_split=0.2, batch_size=64, epochs=15, verbose=0)
    
    expected.append(Y[j:k])
    observed.append(model.predict(X[j:k]))
    times.append(tm.time() - start)
    
    if VERBOSITY:
      plot_history(hist, f"{name} ({str(len(times)).zfill(2)} of {len(pointers)})")
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""## GRU"""

from keras.layers import GRU

def create_gru(input_shape):
  model = Sequential()
  
  model.add(GRU(50, activation='relu', input_shape=input_shape))
  model.add(Dense(1, activation='sigmoid' if NORMALIZE else 'relu'))
  
  model.compile(optimizer='adam', loss='mse', metrics = ["accuracy"])
  
  return model

def gru (data, isMulti): 
  global result_data
  
  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)
  
  name = "GRU Multivariate" if isMulti else "GRU Univariate"
  
  model = create_gru((X.shape[1], X.shape[2]))

  expected, observed, times = [], [], []
  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)
  
  for i, j, k in pointers:
    start = tm.time()
    
    hist = model.fit(X[i:j], Y[i:j], validation_split=0.2, batch_size=64, epochs=15, verbose=0)
    
    expected.append(Y[j:k])
    observed.append(model.predict(X[j:k]))
    times.append(tm.time() - start)
    
    if VERBOSITY:
      plot_history(hist, f"{name} ({str(len(times)).zfill(2)} of {len(pointers)})")
    
  result_data['results'][name] = evaluate(expected, observed, times, name)
  
  if VERBOSITY:
    plot_prediction(expected, observed, name)

"""# Storage Util"""

def print_json ():
  print(json.dumps(result_data, sort_keys=True, indent=4))

def store_results ():
  name = int(tm.time())
  
  result_data['meta'] = {
    "SEEABLE_PAST": SEEABLE_PAST,
    "PREDICT_IN_FUTURE": PREDICT_IN_FUTURE,
    "FLOW_INTERVAL": FLOW_INTERVAL,
    "NORMALIZE": NORMALIZE,
    "SET_SPLIT": SET_SPLIT,
    "TEST_SPLIT": TEST_SPLIT,
    "VALIDATION_SPLIT": VALIDATION_SPLIT,
  }
  
  with open(f"{PATH}results/{name}.json", 'w') as json_file:
    json.dump(result_data, json_file, sort_keys=True, indent=4)
    
  slim_result_data = copy.deepcopy(result_data)
  for model in slim_result_data['results']:
      del slim_result_data['results'][model]['raw']
    
  with open(f"{PATH}results/{name}_slim.json", 'w') as json_file:
    json.dump(slim_result_data, json_file, sort_keys=True, indent=4)

def store_comparisons (title):
  name = str(int(tm.time()))
  
  j = copy.deepcopy(comparison_data)
  
  with open(f"{PATH}results/comparison/{name+title}.json", 'w') as json_file:
    json.dump(j, json_file, sort_keys=True, indent=4)
    
  
  for i in range(len(j)):
    print([*j[i]['results']])
    for model in j[i]['results']:
      del j[i]['results'][model]['raw']
    
    
  with open(f"{PATH}results/comparison/{name+title}_slim.json", 'w') as json_file:
    json.dump(j, json_file, sort_keys=True, indent=4)

def load_comparison(filename):
  global comparison_data
  
  with open(f"{PATH}results/comparison/{filename}.json", 'r') as json_file:
    comparison_data = json.load(json_file)

"""# Plot Util"""

def plot_performance(metric, y_label, title):
  """ Plot Performance
  
  Plot a bar graph of the performance of some metric
  
  Arguments:
    metric: the name of the property of the metric
    y_label: the name of the label of the metric
    title: the title of the plot
  """
  
  path = f"{PATH}plots/performances/bars/{title}"
  
  models = tuple(result_data['results'].keys())
  y_pos = np.arange(len(models))
  performance = [v[metric] for v in result_data['results'].values()]

  plt.rcdefaults()
  plt.bar(y_pos, performance, align='center', alpha=0.5)
  plt.xticks(y_pos, models, rotation=90)
  plt.ylabel(y_label)
  plt.title(title)

  plt.savefig(path + ".png", bbox_inches='tight')
  plt.savefig(path + ".pdf")
  
  if SHOW_PLOT:
    plt.show()
    
  plt.close('all')

def plot_performance_improved(metric, y_label, title):
  """ Plot Performance Improved
  
  Plot a box graph of the performance of some metric
  
  Arguments:
    metric: the name of the property of the metric
    y_label: the name of the label of the metric
    title: the title of the plot
  """
  
  path = f"{PATH}plots/performances/boxes/{title}"
  
  fig, ax_plot = plt.subplots()
  
  ax_plot.set_title(title)
  ax_plot.set_xlabel(y_label)
  ax_plot.set_ylabel('Model')
  
  bplot = ax_plot.boxplot([v['raw'][metric] for v in result_data['results'].values()], vert=False)
  ax_plot.set_yticklabels(list(result_data['results'].keys()))
  
  plt.savefig(path + ".png", bbox_inches='tight')
  plt.savefig(path + ".pdf")
  
  if SHOW_PLOT:
    plt.show()
    
  plt.close('all')

def plot_precision_bucket ():
  """ Plot Precision Bucket 
  
  Plot a stack box graph of the precision mesuared by the buckets.
  
  """
  
  path = f"{PATH}plots/precision"
  
  N = len(result_data['results'])
    
  ind = np.arange(N)    # the x locations for the groups
  width = 0.35       # the width of the bars: can also be len(x) sequence
  
  pre = []
  bott = []
  
  models = list(result_data['results'].keys())

  n_buckets = len(result_data['results'][models[0]]['PRE'])
    
  for i in range(n_buckets):
    pre.append([v["PRE"][i] for v in result_data['results'].values()])
    
    if i == 0:
      bott.append([0] * N)
    else:
      bott.append([bott[i-1][j] + pre[i-1][j]  for j in range(N)])
  
  p = []
  leg_lin = []
  leg_lab = []
  
  for i in range(n_buckets):
    _p = plt.bar(ind, tuple(pre[i]), width, bottom=tuple(bott[i]))
    
    leg_lin.append(_p[0])
    leg_lab.append(f"Bucket of {2**i}")
    p.append(_p)

  plt.ylabel('Scores')
  plt.title('Precision by model and bucket')
  plt.xticks(ind, list(result_data['results'].keys()), rotation=90)
  plt.yticks(np.arange(0, 1.05, 0.05))
  plt.legend(tuple(leg_lin), tuple(leg_lab))
  
  plt.savefig(path + ".png", bbox_inches='tight')
  plt.savefig(path + ".pdf")

  if SHOW_PLOT:
    plt.show()

  plt.close('all')

"""# Comparison Util"""

def plot_results_comparison(name, xlabel, xticks, metric):
  path = f"{PATH}plots/{name.lower().replace(' ', '_')}_{metric.lower()}"
  models = [*comparison_data[0]['results']]
  
  for model in models:
    datapoints = [result['results'][model][metric] for result in comparison_data]
    plt.plot(datapoints) 

  plt.title(name)
  plt.ylabel(metric)
  plt.xlabel(xlabel)
  plt.xticks(np.arange(len(xticks)), xticks)
  plt.legend(models, loc='upper left')
  plt.rcdefaults()

  plt.savefig(path + ".png", bbox_inches='tight')
  plt.savefig(path + ".pdf")

  if SHOW_PLOT:
    plt.show()
    
  plt.close('all')

def compare_results_by_window_split(values):
  global SET_SPLIT
  global VERBOSITY
  global result_data
  global comparison_data
  
  aux = SET_SPLIT
  
  VERBOSITY = False
  
  result_data = {
      'results': {},
      'meta': {}
  }
  
  comparison_data = []

  for value in values:
    start = tm.time()
    
    SET_SPLIT = value

#     random_guess_univariate(data)
    moving_average(data)
    naive(data)
#     logistic_regression(data, False)
#     logistic_regression(data, True)
    random_forest(data, False)
    random_forest(data, True)
    support_vector_machine(data, False)
    support_vector_machine(data, True)
    rnn(data, False)
    rnn(data, True)
    lstm(data, False)
    lstm(data, True)
    gru(data, False)
    gru(data, True)
    
    comparison_data.append(copy.deepcopy(result_data))
    
    print(f"({len(comparison_data)} of {len(values)}) Finished Running with SET_SPLIT {value} in {tm.time() - start} seconds")

  store_comparisons('_window_split_comparison')
  
  SET_SPLIT = aux

def compare_results_by_seeable_past(values):
  global SEEABLE_PAST
  global N_STEPS
  global VERBOSITY
  global result_data
  global comparison_data
  
  aux = SEEABLE_PAST
  
  VERBOSITY = False
  
  result_data = {
      'results': {},
      'meta': {}
  }
  
  comparison_data = []

  for value in values:
    start = tm.time()
    
    SEEABLE_PAST = value
    N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL

#     random_guess_univariate(data)
    moving_average(data)
    naive(data)
#     logistic_regression(data, False)
#     logistic_regression(data, True)
    random_forest(data, False)
    random_forest(data, True)
    support_vector_machine(data, False)
    support_vector_machine(data, True)
    rnn(data, False)
    rnn(data, True)
    lstm(data, False)
    lstm(data, True)
    gru(data, False)
    gru(data, True)
    
    comparison_data.append(copy.deepcopy(result_data))
    
    print(f"({len(comparison_data)} of {len(values)}) Finished Running with SEEABLE_PAST {value} in {tm.time() - start} seconds")

  store_comparisons('_seeable_past_comparison')
  
  SEEABLE_PAST = aux
  N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL

def compare_results_by_flow_interval(values):
  global FLOW_INTERVAL
  global N_STEPS
  global N_FUTURE
  global DAY_SIZE
  global WEEK_SIZE
  global VERBOSITY
  global result_data
  global comparison_data
  
  aux = FLOW_INTERVAL
  
  VERBOSITY = False
  
  result_data = {
      'results': {},
      'meta': {}
  }
  
  comparison_data = []

  for value in values:
    start = tm.time()
    
    FLOW_INTERVAL = value
    N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL
    N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL
    DAY_SIZE = (24 * 3600) // FLOW_INTERVAL  
    WEEK_SIZE = 7 * DAY_SIZE

#     random_guess_univariate(data)
    moving_average(data)
    naive(data)
#     logistic_regression(data, False)
#     logistic_regression(data, True)
    random_forest(data, False)
    random_forest(data, True)
    support_vector_machine(data, False)
    support_vector_machine(data, True)
    rnn(data, False)
    rnn(data, True)
    lstm(data, False)
    lstm(data, True)
    gru(data, False)
    gru(data, True)
    
    comparison_data.append(copy.deepcopy(result_data))
    
    print(f"({len(comparison_data)} of {len(values)}) Finished Running with FLOW_INTERVAL {value} in {tm.time() - start} seconds")

  store_comparisons('_flow_interval_comparison')
  
  FLOW_INTERVAL = aux
  N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL
  N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL
  DAY_SIZE = (24 * 3600) // FLOW_INTERVAL  
  WEEK_SIZE = 7 * DAY_SIZE

def compare_results_by_predict_in_future(values):
  global PREDICT_IN_FUTURE
  global N_FUTURE
  global VERBOSITY
  global result_data
  global comparison_data
  
  aux = PREDICT_IN_FUTURE
  
  VERBOSITY = False
  
  result_data = {
      'results': {},
      'meta': {}
  }
  
  comparison_data = []

  for value in values:
    start = tm.time()
    
    PREDICT_IN_FUTURE = value
    N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL

#     random_guess_univariate(data)
    moving_average(data)
    naive(data)
#     logistic_regression(data, False)
#     logistic_regression(data, True)
    random_forest(data, False)
    random_forest(data, True)
    support_vector_machine(data, False)
    support_vector_machine(data, True)
    rnn(data, False)
    rnn(data, True)
    lstm(data, False)
    lstm(data, True)
    gru(data, False)
    gru(data, True)
    
    comparison_data.append(copy.deepcopy(result_data))
    
    print(f"({len(comparison_data)} of {len(values)}) Finished Running with PREDICT_IN_FUTURE {value} in {tm.time() - start} seconds")

  store_comparisons('_predict_future_comparison')
  
  PREDICT_IN_FUTURE = aux
  N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL

"""# Train&Test

Run all the models and store the results at the end
"""

# Model Parameters

SEEABLE_PAST = 180 # in minutes

PREDICT_IN_FUTURE = 15 # in minutes

FLOW_INTERVAL = 450 # the interval size for each flow

NORMALIZE = True #Decide if we gonna use normalized flow and speed values, or not

SET_SPLIT = 0.65

TEST_SPLIT = 0.2

VALIDATION_SPLIT = 0.2

# Derivated Model Parameters

N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL # the number of flows to see in the past

N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL # how much in the future we want to predict (0 = predict the flow on the next 5 minutes)

DAY_SIZE = (24 * 3600) // FLOW_INTERVAL  

WEEK_SIZE = 7 * DAY_SIZE

result_data = {
    'results': {},
    'meta': {}
}

comparison_data = []

all_data = retrieve_data(VERBOSITY)

data = clean_data(all_data, VERBOSITY)

random_forest_grid(data, False)

support_vector_machine_grid(data, False)

#random_guess_univariate(data)

moving_average(data)

naive(data)

#logistic_regression(data, False)

#logistic_regression(data, True)

random_forest(data, False)

random_forest(data, True)

support_vector_machine(data, False)

support_vector_machine(data, True)

rnn(data, False)

rnn(data, True)

lstm(data, False)

lstm(data, True)

gru(data, False)

gru(data, True)

store_results()

#plot_precision_bucket()

plot_performance_improved('TIME', 'Seconds', 'Training Time Comparison')

plot_performance_improved('RMSE', 'RMSE', 'Root Mean Square Error Comparison')

plot_performance_improved('NRMSE', 'NRMSE', 'Normalized Root Mean Square Error Comparison')

plot_performance_improved('MAE', 'MAE', 'Max Absolute Error Comparison')

plot_performance_improved('HR', 'Percentage', 'Hit Ratio Comparison')

# load_comparison("1571844839_predict_future_comparison_slim")
# VERBOSITY = True

predict_futures = [15, 30, 45, 60]
compare_results_by_predict_in_future(predict_futures)

plot_results_comparison('Predict Future for Training Comparison', 'Time in the Future in Minutes', predict_futures, 'NRMSE')

plot_results_comparison('Predict Future for Training Comparison', 'Time in the Future in Minutes', predict_futures, 'RMSE')

plot_results_comparison('Predict Future for Training Comparison', 'Time in the Future in Minutes', predict_futures, 'MAE')

flow_intervals = [150, 300, 450]
compare_results_by_flow_interval(flow_intervals)

plot_results_comparison('Flow Interval for Training Comparison', 'Flow Size in Seconds', flow_intervals, 'NRMSE')

plot_results_comparison('Flow Interval for Training Comparison', 'Flow Size in Seconds', flow_intervals, 'RMSE')

plot_results_comparison('Flow Interval for Training Comparison', 'Flow Size in Seconds', flow_intervals, 'MAE')

seeable_pasts = [60, 120, 180, 210, 240, 270, 300, 360, 420]
compare_results_by_seeable_past(seeable_pasts)

plot_results_comparison('Seeable Past for Training Comparison', 'Seeable Past in Seconds', seeable_pasts, 'NRMSE')

plot_results_comparison('Seeable Past for Training Comparison', 'Seeable Past in Seconds', seeable_pasts, 'RMSE')

plot_results_comparison('Seeable Past for Training Comparison', 'Seeable Past in Seconds', seeable_pasts, 'MAE')

window_splits = [0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85]
compare_results_by_window_split(window_splits)

plot_results_comparison('Windows Size for Training Comparison', 'Window Size', window_splits, 'NRMSE')

plot_results_comparison('Windows Size for Training Comparison', 'Window Size', window_splits, 'RMSE')

plot_results_comparison('Windows Size for Training Comparison', 'Window Size', window_splits, 'MAE')

"""# Observations:

+ For the evaluation of the RNN and it's variations was used the Walking Forward methodology so that we had many test sessions and all training sessions where the same size [[1]](https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9)
"""