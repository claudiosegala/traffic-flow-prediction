{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tcc.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tD29g6RmWyjg",
        "xw1p5NfaMKTk",
        "rlQKvD3_tqxd",
        "Y6MvTTexQML5",
        "0CR6HLKUUWvh",
        "8BkdL8EE5pl3",
        "5atl1RAeso-d",
        "j2hH4Og160vf",
        "HwDC7WBEOf_H",
        "ZGgV2YkoYA_W",
        "GVUHvQxwWVrW",
        "B3dQ_nM_TgDC",
        "D7Nq3PsMTjYc",
        "qhaufggBRABt",
        "d7RYTwKXkP4o",
        "b1QmFwC1k2NO"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiosegala/Monografia/blob/master/code/tcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxA-9RZf1SXs",
        "colab_type": "text"
      },
      "source": [
        "# TCC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krd1GCLFBNn3",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive\n",
        "\n",
        "Connect to Google Drive of 'alfredcoinworth'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebzVayUNBP2L",
        "colab_type": "code",
        "outputId": "3c563c78-41df-407b-88b3-7f6bf4f80589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import google as g # To connect with google drive\n",
        "g.colab.drive.mount('/content/drive')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD29g6RmWyjg",
        "colab_type": "text"
      },
      "source": [
        "# Retrieve and Instanciate Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FebihZqH2eDt",
        "colab_type": "text"
      },
      "source": [
        "For this work, we will need these libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUNNEdAWJPx",
        "colab_type": "code",
        "outputId": "e57c4e42-a6df-4aad-a12c-58d565b2241c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install keras\n",
        "!pip install statsmodels"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.1.7)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.17.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.17.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD11PvxQXFT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "aa4e93a3-3179-4940-a3a5-6a185f6d5d4c"
      },
      "source": [
        "import tensorflow as tf # machine learning library\n",
        "import pandas as pd # data manipulation library\n",
        "import matplotlib.pyplot as plt # plot library\n",
        "import numpy as np # math library\n",
        "import datetime as dt # to discover week day\n",
        "import time as tm # to convert to seconds\n",
        "import sklearn as skl # regression templates library\n",
        "import sklearn.metrics as sklm # metrics\n",
        "import statsmodels.api as sma # statistical models api\n",
        "import statistics as st # statistics\n",
        "import statsmodels as sm # statistical models\n",
        "\n",
        "import random\n",
        "import math\n",
        "import json\n",
        "import copy\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw1p5NfaMKTk",
        "colab_type": "text"
      },
      "source": [
        "# Configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyxvqpIMMXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2UhjEKrdBy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYzBzzwQdI0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.set_random_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSAe5FQViqH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucIY4qrziqOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sS94hovWAbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/TCC/' # ''\n",
        "\n",
        "VERBOSITY = True\n",
        "\n",
        "SHOW_PLOT = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlQKvD3_tqxd",
        "colab_type": "text"
      },
      "source": [
        "# General Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfu0MDu3jUmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten (m):\n",
        "  \"\"\" Flatten\n",
        "  \n",
        "  Transform a matrix in an array.\n",
        "  \n",
        "  Arguments:\n",
        "    m: the matrix to be flatten\n",
        "  \"\"\"\n",
        "  \n",
        "  return [i for sl in m for i in sl]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llW_Qq7sZk1U",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Retrieval Util\n",
        "\n",
        "This phase we have to get the data stored in Google Drive and transform into a dataset for prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSG8FE3wRyOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retrieve_data(verbosity):\n",
        "  path = f\"{PATH}dataset/all_data_sorted.csv\"\n",
        "  \n",
        "  col_names = [\n",
        "    'Sensor',\n",
        "    'Date',\n",
        "    'Time',\n",
        "    'Lane',\n",
        "    'Speed',\n",
        "    'Max Speed',\n",
        "    'Size'\n",
        "  ]\n",
        "  \n",
        "  data = pd.read_csv(path, ';', header=None, names=col_names)\n",
        "  \n",
        "  if verbosity:\n",
        "    print(f\"It contains {len(data['Sensor'])} entries\\n\\n\")\n",
        "    print(data.head(), end=\"\\n\\n\")\n",
        "    print(data.describe(), end=\"\\n\\n\")\n",
        "    \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxfcVFLfRFpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(data, verbosity):\n",
        "  if verbosity:\n",
        "    print(f\"This dataset contains {len(set(data['Sensor']))} sensors.\")\n",
        "    print(f\"We will be using only one.\")\n",
        "  \n",
        "  # Extract data from just one sensor\n",
        "  data = data[data['Sensor'] == 'RSI128']\n",
        "  \n",
        "  # Remove unnecessary columns\n",
        "  data = data.drop(columns=['Sensor','Lane','Max Speed','Size'])\n",
        "  \n",
        "  data['Date'] = pd.to_datetime(data['Date'], format='%Y/%m/%d')\n",
        "   \n",
        "  # Adjust type\n",
        "  f = lambda x : tm.strptime(x, '%H:%M:%S')\n",
        "  data['Time'] = data['Time'].apply(f)\n",
        "  \n",
        "  g = lambda x : dt.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()\n",
        "  data['Time'] = data['Time'].apply(g)\n",
        "  \n",
        "  h = lambda x : int(x)\n",
        "  data['Time'] = data['Time'].apply(h)\n",
        "  \n",
        "  i = lambda x : float(x)\n",
        "  data['Speed'].apply(i)\n",
        "  \n",
        "  # Create week day from date\n",
        "  j = lambda x : x.weekday()\n",
        "  data['WeekDay'] = data['Date'].apply(j)\n",
        "  \n",
        "  if verbosity:\n",
        "    for col, cont in data.iteritems():\n",
        "        print(f\"Column {col} has {cont.isnull().sum()} null elements\")\n",
        "        print(f\"Column {col} has {cont.isna().sum()} nan elements\")\n",
        "        \n",
        "    print()\n",
        "        \n",
        "    start = data['Date'].min()\n",
        "    end = data['Date'].max()\n",
        "    print(f\"This data is from <{start}> to <{end}>. {(end - start).days + 1} days.\\n\")\n",
        "\n",
        "    print(f\"It contains {len(data['Date'])} entries\\n\\n\")\n",
        "\n",
        "    print(data.head(), end=\"\\n\\n\")\n",
        "    print(data.describe(), end=\"\\n\\n\")\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6MvTTexQML5",
        "colab_type": "text"
      },
      "source": [
        "# Flow Generation Util\n",
        "\n",
        "The plot is based on [A Guide to Time Series Visualization with Python 3](https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-visualization-with-python-3).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmF8FxOBB2T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_flow(flow_series, flow_interval):\n",
        "  \"\"\" Plot of Flow\n",
        "  \n",
        "  Plot the flow from week to week\n",
        "  \n",
        "  Arguments:\n",
        "    flow_series: an array of flows\n",
        "    flow_interval: the interval in which the flow was made\n",
        "  \"\"\"\n",
        "\n",
        "  n = len(flow_series) // WEEK_SIZE\n",
        "\n",
        "  if len(flow_series) % WEEK_SIZE == 0:\n",
        "    print('Yey')\n",
        "\n",
        "  for i in range(n):\n",
        "    s = WEEK_SIZE * i\n",
        "    e = min(s + WEEK_SIZE, len(flow_series))\n",
        "    path = f\"{PATH}plots/flow/flow_{flow_interval}_week_{str(i+1).zfill(2)}\"\n",
        "\n",
        "    plt.plot(flow_series[s:e])\n",
        "\n",
        "    plt.title(f\"Flow ({flow_interval}s) - Week {i+1}\")\n",
        "    plt.ylabel('Flow')\n",
        "    plt.xlabel('Time')\n",
        "    plt.rcdefaults()\n",
        "    \n",
        "    plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "    plt.savefig(path + \".pdf\")\n",
        "    \n",
        "    #plt.show(name + \"ind\")\n",
        "    plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDHY5vXtQlHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_flow_decomposition(flow_series, freq):\n",
        "  path = f\"{PATH}plots/flow/seasonal_decompose\"\n",
        "  \n",
        "  decompose = sm.tsa.seasonal.seasonal_decompose\n",
        "  decomposition = decompose(flow_series, model='additive', freq=freq)\n",
        "  fig = decomposition.plot()\n",
        "\n",
        "  plt.rcdefaults()\n",
        "#   plt.plot()\n",
        "  \n",
        "  plt.savefig(path + \".png\")\n",
        "  plt.savefig(path + \".pdf\")\n",
        "  \n",
        "  if SHOW_PLOT:\n",
        "    plt.show()\n",
        "    \n",
        "  plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJzIdrHk3w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_flow_data(n, accSpeed, weekDay):\n",
        "  avgSpeed = (accSpeed // n) if n else 0\n",
        "  density = (n / avgSpeed) if avgSpeed else 0\n",
        "  w = [(1 if weekDay == i else 0) for i in range(7)] # weekday\n",
        "  \n",
        "  return (n, density, avgSpeed, w[0], w[1], w[2], w[3], w[4], w[5], w[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-x0DKOmMnmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_flow (data, flow_interval, normalize, verbosity):\n",
        "  date = np.asarray(data['Date'])\n",
        "  weekDay = np.asarray(data['WeekDay'])\n",
        "  time = np.asarray(data['Time'])\n",
        "  speed = np.asarray(data['Speed'])\n",
        "  \n",
        "  dateControl = date[0]\n",
        "  timeBlock = flow_interval\n",
        "  countFlow = 0\n",
        "  accSpeed = 0\n",
        "  flowData = []\n",
        "\n",
        "  for i in range(len(date)):\n",
        "    if time[i] >= timeBlock: # init a new time block\n",
        "      flowData.append(get_flow_data(countFlow, accSpeed, weekDay[i])) \n",
        "      timeBlock += flow_interval\n",
        "      accSpeed = 0\n",
        "      countFlow = 0\n",
        "      \n",
        "    if date[i] > dateControl: # reset on day change\n",
        "      dateControl = date[i]\n",
        "      timeBlock = flow_interval \n",
        "      countFlow = 0\n",
        "      accSpeed = 0\n",
        "      \n",
        "    if time[i] < timeBlock: # add car on flow\n",
        "      countFlow += 1\n",
        "      accSpeed += speed[i]\n",
        "\n",
        "  k = (DAY_SIZE - (len(flowData) % DAY_SIZE)) % DAY_SIZE\n",
        "\n",
        "  for i in range(k):\n",
        "    flowData.append(get_flow_data(0, 0, weekDay[len(date) - 1])) \n",
        "      \n",
        "  flowDataColumns = [\n",
        "    'Flow',\n",
        "    'Density',\n",
        "    'AveSpeed',\n",
        "    'Sunday',\n",
        "    'Monday',\n",
        "    'Tuesday',\n",
        "    'Wednesday',\n",
        "    'Thursday',\n",
        "    'Friday',\n",
        "    'Saturday',\n",
        "  ]\n",
        "  \n",
        "  flowData = pd.DataFrame(flowData, columns=flowDataColumns)\n",
        "  \n",
        "  if normalize:\n",
        "    scaler = skl.preprocessing.MinMaxScaler(feature_range=(0,1))\n",
        "    flowDataScaled = scaler.fit_transform(flowData)  \n",
        "    flowData = pd.DataFrame(flowDataScaled, columns=flowData.columns, index=flowData.index)\n",
        "  \n",
        "  if verbosity:\n",
        "    plot_flow(flowData['Flow'], flow_interval)\n",
        "\n",
        "    plot_flow_decomposition(flowData['Flow'], WEEK_SIZE)\n",
        "\n",
        "    print(flowData.describe())\n",
        "  \n",
        "  return flowData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg_ctoO2vNol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analise_flow(data, flow_interval):\n",
        "  _ = get_flow(data, flow_interval, False, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CR6HLKUUWvh",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Generation Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyFfRVeyUdWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "def split_sequence(sequence, isMulti, n_steps, n_future):\n",
        "  \"\"\" Split Sequence\n",
        "  \n",
        "  Split a sequence in rolling intervals with a corresponding value \n",
        "  like the example bellow.\n",
        "  \n",
        "  Ex: split_sequence([1, 2, 3, 4, 5], 3) #([[1, 2, 3], [2, 3, 4]], [4, 5])\n",
        "  \n",
        "  Arguments:\n",
        "    sequence: the sequence to split.\n",
        "    isMulti: if the data is multivariate or not.\n",
        "    n_steps: size of the rolling interval\n",
        "    n_future: the distance to the interval the value should be.  \n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(sequence)\n",
        "  X, Y = list(), list()\n",
        "  \n",
        "  for i in range(n):\n",
        "    j = i + n_steps\n",
        "    k = j + n_future\n",
        "\n",
        "    if k >= n:\n",
        "      break\n",
        "\n",
        "    seq_x, seq_y = sequence[i:j], sequence[k]\n",
        "    X.append(seq_x)\n",
        "    Y.append(seq_y[0] if isMulti else seq_y)\n",
        "\n",
        "  return np.array(X), np.array(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hts8_IFUf5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_flow (raw_seq, isMulti, n_steps, n_future, verbosity): \n",
        "  \"\"\" Reshape Flow\n",
        "  \n",
        "  Reshape a sequence in rolling intervals from [samples, timesteps] into \n",
        "  [samples, timesteps, features].\n",
        "  \n",
        "  Arguments:\n",
        "    raw_seq: the sequence to reshape.\n",
        "    isMulti: if the data is multivariate or not.\n",
        "    n_steps: size of the rolling interval\n",
        "    n_future: the distance to the interval the value should be.  \n",
        "  \"\"\"\n",
        "  \n",
        "  X, Y = split_sequence(np.array(raw_seq), isMulti, n_steps, n_future)\n",
        "  \n",
        "  \n",
        "  if not isMulti:\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "    \n",
        "  if verbosity:\n",
        "    print(f\"X Shape: {X.shape}\")\n",
        "    print(f\"Y Shape: {Y.shape}\")\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BkdL8EE5pl3",
        "colab_type": "text"
      },
      "source": [
        "# Storage Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OWaLFzKSG2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_json (obj):\n",
        "  print(json.dumps(obj, sort_keys=True, indent=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51LJBT3fgdEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_results_json ():\n",
        "  print(json.dumps(result_data, sort_keys=True, indent=4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeBEPq-GmCvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store(obj, path, name):\n",
        "  with open(f\"{PATH}{path}/{name}.json\", 'w') as json_file:\n",
        "    json.dump(obj, json_file, sort_keys=True, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4OjfpS8R-ZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_results ():\n",
        "  name = int(tm.time())\n",
        "  \n",
        "  result_data['meta'] = {\n",
        "    \"SEEABLE_PAST\": SEEABLE_PAST,\n",
        "    \"PREDICT_IN_FUTURE\": PREDICT_IN_FUTURE,\n",
        "    \"FLOW_INTERVAL\": FLOW_INTERVAL,\n",
        "    \"NORMALIZE\": NORMALIZE,\n",
        "    \"SET_SPLIT\": SET_SPLIT,\n",
        "    \"TEST_SPLIT\": TEST_SPLIT,\n",
        "    \"VALIDATION_SPLIT\": VALIDATION_SPLIT,\n",
        "  }\n",
        "  \n",
        "  with open(f\"{PATH}results/{name}.json\", 'w') as json_file:\n",
        "    json.dump(result_data, json_file, sort_keys=True, indent=4)\n",
        "    \n",
        "  slim_result_data = copy.deepcopy(result_data)\n",
        "  for model in slim_result_data['results']:\n",
        "      del slim_result_data['results'][model]['raw']\n",
        "    \n",
        "  with open(f\"{PATH}results/{name}_slim.json\", 'w') as json_file:\n",
        "    json.dump(slim_result_data, json_file, sort_keys=True, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_UiuJG3GwME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def store_comparisons (title):\n",
        "  name = str(int(tm.time()))\n",
        "  \n",
        "  j = copy.deepcopy(comparison_data)\n",
        "  \n",
        "  with open(f\"{PATH}results/comparison/{name+title}.json\", 'w') as json_file:\n",
        "    json.dump(j, json_file, sort_keys=True, indent=4)\n",
        "    \n",
        "  \n",
        "  for i in range(len(j)):\n",
        "    print([*j[i]['results']])\n",
        "    for model in j[i]['results']:\n",
        "      del j[i]['results'][model]['raw']\n",
        "    \n",
        "    \n",
        "  with open(f\"{PATH}results/comparison/{name+title}_slim.json\", 'w') as json_file:\n",
        "    json.dump(j, json_file, sort_keys=True, indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxdr6XZzVdY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_comparison(filename):\n",
        "  global comparison_data\n",
        "  \n",
        "  with open(f\"{PATH}results/comparison/{filename}.json\", 'r') as json_file:\n",
        "    comparison_data = json.load(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cybdNn4R3AW6",
        "colab_type": "text"
      },
      "source": [
        "# Models Util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQ-2RhUqtZu",
        "colab_type": "text"
      },
      "source": [
        "## Misc\n",
        "\n",
        "Function to help implement the training and evaluation of the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu5Wz92BHMmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history (history, name):\n",
        "  \"\"\" Plot of History\n",
        "  \n",
        "  Plot the history of loss in the training session of a model\n",
        "  \n",
        "  Arguments:\n",
        "    history: the history returned by Keras fit of a model\n",
        "    name: the name of the model\n",
        "  \"\"\"\n",
        "  \n",
        "  path = f\"{PATH}plots/history/{name}\"\n",
        "  \n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(name + ' Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.rcdefaults()\n",
        "  \n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.savefig(path + \".pdf\")\n",
        "  \n",
        "  #plt.show(name + \"ind\")\n",
        "  plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei04VHAwH0Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_prediction (Y, Y_hat, title):\n",
        "  \"\"\" Plot Prediction\n",
        "  \n",
        "  Plot the prediction (Flow x Time) of what was expected and what\n",
        "  was predicted.\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  Y = flatten(Y)\n",
        "  Y_hat = flatten(Y_hat)\n",
        "  n = math.floor(len(Y) / DAY_SIZE)\n",
        "  \n",
        "  for r in range(n):\n",
        "    i = r * DAY_SIZE\n",
        "    j = min(i + DAY_SIZE, len(Y))\n",
        "    \n",
        "    name = f\"{title} ({str(r+1).zfill(2)} of {n})\"\n",
        "    path = f\"{PATH}plots/prediction/{name}\"\n",
        "    \n",
        "    plt.plot(Y[i:j])\n",
        "    plt.plot(Y_hat[i:j])\n",
        "    plt.title(title + 'Prediction')\n",
        "    plt.ylabel('Flow')\n",
        "    plt.xlabel('Time')\n",
        "    plt.legend(['actual', 'prediction'], loc='upper left')\n",
        "    plt.rcdefaults()\n",
        "\n",
        "    plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "    plt.savefig(path + \".pdf\")\n",
        "\n",
        "    plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH648TIGLVKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset (n, window_split, test_split):\n",
        "  \"\"\" Dataset Split\n",
        "  \n",
        "  Generate pointers for the training and test of the models based\n",
        "  on the splits.\n",
        "  \n",
        "  Arguments:\n",
        "    n: size of the dataset.\n",
        "    window_split: percentage of the dataset that will be used in each \n",
        "      train&test sample.\n",
        "    test_split: percentage of the train&test sample that will be \n",
        "      dedicated to testing.\n",
        "  \"\"\"\n",
        "  \n",
        "  sz_window = int(n * window_split)\n",
        "  sz_test = int(sz_window * test_split)\n",
        "  sz_train = sz_window - sz_test\n",
        "  sz_jump = sz_test\n",
        "\n",
        "  i, j, k = 0, sz_train, min(n, sz_train + sz_test)\n",
        "  \n",
        "  res = []\n",
        "  \n",
        "  while j < n:\n",
        "    res.append((i, j, k))\n",
        "    \n",
        "    i = i + sz_jump\n",
        "    j = i + sz_train\n",
        "    k = min(n, j + sz_test)\n",
        "    \n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Zypk5Cbiv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_precision_hit_ratio (Y, Y_hat):\n",
        "  \"\"\" Trend Prediction Ratio Calculation\n",
        "  \n",
        "  Calculates the ratio of up/down prediction.\n",
        "  \n",
        "  Arguments:\n",
        "    Y: the expected dataset.\n",
        "    Y_hat: the observed dataset.\n",
        "  \"\"\"\n",
        "  \n",
        "  cnt = 0\n",
        "  \n",
        "  for i in range(len(Y)):\n",
        "    if i < N_FUTURE:\n",
        "      continue\n",
        "      \n",
        "    exp = Y[i] - Y[i - N_FUTURE]\n",
        "    obs = Y_hat[i] - Y[i - N_FUTURE]\n",
        "    \n",
        "    if exp * obs > 0:\n",
        "      cnt += 1\n",
        "    \n",
        "  return cnt / len(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTes33wAe1zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_precision_bucket (Y, Y_hat):\n",
        "  \"\"\" Precision Bucket Calculation\n",
        "  \n",
        "  Counts how many of the prediction got wronng by at most 2Ë†x, x \n",
        "  being the bucket. There are 7 buckets, that is, the maximum error \n",
        "  calculated is 128.\n",
        "  \n",
        "  Arguments:\n",
        "    Y: the expected dataset.\n",
        "    Y_hat: the observed dataset.\n",
        "  \"\"\"\n",
        "  \n",
        "  n = 7 # the number of buckets\n",
        "  buckets = [0] * n\n",
        "  \n",
        "  for i in range(len(Y)):\n",
        "    diff = abs(Y[i] - Y_hat[i])\n",
        "    \n",
        "    for i in range (n):\n",
        "      if diff <= 2**i:\n",
        "        buckets[i] += 1\n",
        "        break\n",
        "\n",
        "  for i in range (n):\n",
        "     buckets[i] = buckets[i] / len(Y)\n",
        "\n",
        "  return tuple(buckets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u6hphOb8AQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_raw (expected, observed, times):\n",
        "  \"\"\" Evaluate Raw Sessions \n",
        "  \n",
        "  Evaluate each of the train&test sessions by RMSE, NRMSE, MAE, HR, PRE. \n",
        "  It will store the results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each train&test session.\n",
        "    observed: an array of observed instances of each train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(expected)\n",
        "\n",
        "  for i in range(n):\n",
        "    observed[i] = [max(o, 0) for o in observed[i]]\n",
        "  \n",
        "  raw = {\n",
        "    'expected': expected,\n",
        "    'observed': observed,\n",
        "    'TIME': times,\n",
        "    'RMSE': [0] * n,\n",
        "    'NRMSE': [0] * n,\n",
        "    'MAE': [0] * n,\n",
        "    'HR': [0] * n,\n",
        "    #'PRE': [0] * n,\n",
        "  }\n",
        "  \n",
        "  for i in range(n):\n",
        "    Y = expected[i]\n",
        "    Y_hat = observed[i]\n",
        "    time = times[i]\n",
        "\n",
        "    raw['MAE'][i] = sklm.mean_absolute_error(Y, Y_hat)\n",
        "    raw['RMSE'][i] = np.sqrt(sklm.mean_squared_error(Y, Y_hat))\n",
        "    raw['NRMSE'][i] = raw['RMSE'][i] / np.std(Y)\n",
        "    raw['HR'][i] = evaluate_precision_hit_ratio(Y, Y_hat)\n",
        "    #raw['PRE'][i] = evaluate_precision_bucket(Y, Y_hat)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      print(f\"({i+1}/{n}) Test Size: {len(Y)}, Time: {time}s\")\n",
        "      print(f\"\\tRMSE: {raw['RMSE'][i]}\")\n",
        "      print(f\"\\tNRMSE: {raw['NRMSE'][i]}\")\n",
        "      print(f\"\\tMAE: {raw['MAE'][i]}\")\n",
        "      print(f\"\\tHit Ratio: {raw['HR'][i] * 100}%\")\n",
        "\n",
        "  return raw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW3-LAmDNpYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate (expected, observed, times, name):\n",
        "  \"\"\" Evaluate Sessions\n",
        "  \n",
        "  Evaluate models by RMSE, NRMSE, MAE, HR, PRE. It will store the \n",
        "  results in a object and return it.\n",
        "  \n",
        "  Arguments:\n",
        "    expected: an array of expected instances of each \n",
        "      train&test session.\n",
        "    observed: an array of observed instances of each \n",
        "      train&test session.\n",
        "    times: an array of the time of each train&test session.\n",
        "    desnormalize: if it should desnormalize the results\n",
        "  \"\"\"\n",
        "  n = len(expected)\n",
        "  \n",
        "  # Make the arrays serializable\n",
        "  expected = list(map(list, expected))\n",
        "  observed = list(map(list, observed))\n",
        "  \n",
        "  for i in range(n):\n",
        "    expected[i] = list(map(float, expected[i]))\n",
        "    observed[i] = list(map(float, observed[i]))\n",
        "  \n",
        "  raw = evaluate_raw(expected, observed, times)\n",
        "  \n",
        "  #n_buckets = len(raw['PRE'])\n",
        "  #_pre = [[pre[i] for pre in raw['PRE']] for i in range(n_buckets)]\n",
        "  \n",
        "  eva = {\n",
        "    'TIME': int(sum(times)),\n",
        "    'RMSE': float(np.mean(raw['RMSE'])),\n",
        "    'NRMSE': float(np.mean(raw['NRMSE'])),\n",
        "    'MAE': float(np.mean(raw['MAE'])),\n",
        "    'HR': float(np.mean(raw['HR'])),\n",
        "    #'PRE': [float(np.mean(p)) for p in _pre],\n",
        "    'has_negative': (min(flatten(observed)) < 0),\n",
        "    'raw': raw\n",
        "  }\n",
        "  \n",
        "  print(f\"\\n{name} Final Result:\")\n",
        "  print(f\"\\tTotal Time: {eva['TIME']}s\")\n",
        "  print(f\"\\tRMSE: {eva['RMSE']}\")\n",
        "  print(f\"\\tNRMSE: {eva['NRMSE']}\")\n",
        "  print(f\"\\tMAE: {eva['MAE']}\")\n",
        "  print(f\"\\tHit Ratio: {eva['HR'] * 100}%\")\n",
        "  #print(f\"\\tPrecision: {eva['PRE']}\")\n",
        "    \n",
        "  return eva"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MsKbDOXEQho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_dataset(data, isMulti, flow_interval, n_step, n_future, normalize, verbosity):\n",
        "  multivariateData = get_flow(data, flow_interval, normalize, False)\n",
        "  univariateData = multivariateData['Flow']\n",
        "  \n",
        "  return reshape_flow(\n",
        "      multivariateData if isMulti else univariateData, \n",
        "      isMulti, \n",
        "      n_step, \n",
        "      n_future, \n",
        "      False\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5atl1RAeso-d",
        "colab_type": "text"
      },
      "source": [
        "## Random (Baseline)\n",
        "\n",
        "This implementation just guess a random number in the [0, 100] interval for every output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Bq_mfg3m8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as rnd # random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4uy_XVyswCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_guess_univariate (data):\n",
        "  global result_data\n",
        "  \n",
        "  X, Y = generate_dataset(data, False, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "\n",
        "  name = \"Random Guess\"\n",
        "  m = max(Y)\n",
        "\n",
        "  expected, observed, times = [], [], []\n",
        "  pointers = split_dataset(len(Y), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "\n",
        "    Y_hat = [rnd.randint(0, m) for i in range(k - j)]\n",
        "\n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(Y_hat)\n",
        "    times.append(tm.time() - start)\n",
        "\n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "\n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2hH4Og160vf",
        "colab_type": "text"
      },
      "source": [
        "## Moving Average (Baseline)\n",
        "\n",
        "This implementation just get the mean of every flow value in the input and place it as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tffuEQJ63Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def moving_average (data):\n",
        "  global result_data\n",
        "  \n",
        "  X, Y = generate_dataset(data, False, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  \n",
        "  name = \"Moving Average\"\n",
        "  expected, observed, times = [], [], []\n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  X = X.reshape(X.shape[0], X.shape[1])\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    Y_hat = [np.mean(x) for x in X[j:k]]\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(Y_hat)\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwDC7WBEOf_H",
        "colab_type": "text"
      },
      "source": [
        "## Naive (Baseline)\n",
        "\n",
        "This implementation just use the last value of input as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1V9y_fZOsj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def naive (data):\n",
        "  global result_data\n",
        "  \n",
        "  X, Y = generate_dataset(data, False, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  \n",
        "  name = \"Naive\"\n",
        "  expected, observed, times = [], [], []\n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  X = X.reshape(X.shape[0], X.shape[1])\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    Y_hat = [x[-1] for x in X[j:k]]\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(Y_hat)\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGgV2YkoYA_W",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbUu54z8YS0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnzW4DwtMbbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression_grid(data, isMulti):\t\t\n",
        "  global result_data\t\t\n",
        "      \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\t\t\n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\t\t\n",
        "        \n",
        "  cv=[(slice(None), slice(None))] # to ignore the cross-validation\t\t\n",
        "  param_grid = {\t\t\n",
        "    \"C\": np.logspace(-3,3,7), \t\t\n",
        "    \"penalty\": [\"l1\",\"l2\"]\t\t\n",
        "  }\t\t\n",
        "      \n",
        "  model = LogisticRegression()\t\t\n",
        "      \n",
        "  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=4, verbose=2)\t\t\n",
        "      \n",
        "  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)\t\t\n",
        "    \n",
        "  gs.fit(X[i:j], Y[i:j])\t\t\n",
        "      \n",
        "  best = gs.best_estimator_\t\t\n",
        "  predictions = best.predict(X[j:k])                         \t\t\n",
        "          \n",
        "  mae = sklm.mean_absolute_error(Y[j:k], predictions)\t\t\n",
        "  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))\t\t\n",
        "  nrmse = rmse / np.std(Y[j:k])\t\t\n",
        "  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)\t\t\n",
        "      \n",
        "  res = {\n",
        "    'params': gs.best_params_,\n",
        "    'results': {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'NRMSE': nrmse,\n",
        "        'HR': hr,\n",
        "    },\n",
        "  }\n",
        "\n",
        "  print_json(res)\n",
        "  store(res, 'results/', 'lr_multi_best_params' if isMulti else 'lr_uni_best_params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvfgRi1GYD7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(data, isMulti):\n",
        "  global result_data\n",
        "  \n",
        "  name = \"LR Multivariate\" if isMulti else \"LR Univariate\"\n",
        "\n",
        "  expected, observed, times = [], [], []\n",
        "\n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "\n",
        "  model = LogisticRegression()\n",
        "\n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    model.fit(X[i:j], Y[i:j])\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(model.predict(X[j:k]))\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVUHvQxwWVrW",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest\n",
        "\n",
        "This implementation is based on [Random Forest Algorithm with Python and Scikit-Learn](https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkk54MXRd6K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouDTRhcmvgWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_forest_grid(data, isMulti):\n",
        "  global result_data\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "    \n",
        "  cv=[(slice(None), slice(None))] # to ignore the cross-validation\n",
        "  param_grid = {\n",
        "    'bootstrap': [True, False],\n",
        "    'max_depth': [30, 40, 50, 60, 70, None],\n",
        "    'max_features': [7, 9, 11, 13],\n",
        "#     'min_samples_leaf': [5, 10, 15],\n",
        "#     'min_samples_split': [5, 10, 15],\n",
        "    'n_estimators': [75, 100, 125, 150, 175]\n",
        "  }\n",
        "  \n",
        "  model = skl.ensemble.RandomForestRegressor(random_state=0)\n",
        "  \n",
        "  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=4, verbose=2)\n",
        "  \n",
        "  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)\n",
        "\n",
        "  gs.fit(X[i:j], Y[i:j])\n",
        "  \n",
        "  best = gs.best_estimator_\n",
        "  predictions = best.predict(X[j:k])                         \n",
        "      \n",
        "  mae = sklm.mean_absolute_error(Y[j:k], predictions)\n",
        "  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))\n",
        "  nrmse = rmse / np.std(Y[j:k])\n",
        "  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)\n",
        "\n",
        "  res = {\n",
        "    'params': gs.best_params_,\n",
        "    'results': {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'NRMSE': nrmse,\n",
        "        'HR': hr,\n",
        "    },\n",
        "  }\n",
        "\n",
        "  print_json(res)\n",
        "  store(res, 'results/', 'rf_multi_best_params' if isMulti else 'rf_uni_best_params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aphhugpvWYkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_forest(data, isMulti):\n",
        "  global result_data\n",
        "  \n",
        "  name = \"RF Multivariate\" if isMulti else \"RF Univariate\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "  \n",
        "  expected, observed, times = [], [], []\n",
        "\n",
        "  model = skl.ensemble.RandomForestRegressor(n_estimators=100, max_features='auto', random_state=0)\n",
        "  \n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    model.fit(X[i:j], Y[i:j])\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(model.predict(X[j:k]))\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WICqU265GQ2",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O3aVV1s5KdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwoErPSUdfvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def support_vector_machine_grid(data, isMulti):\n",
        "  global result_data\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "    \n",
        "  cv=[(slice(None), slice(None))]\n",
        "  param_grid = {\n",
        "    'C': [1, 25, 50, 75, 100],\n",
        "    'gamma': np.logspace(-2, 2, 10),\n",
        "    'kernel': ['rbf', 'linear']\n",
        "  }\n",
        "  \n",
        "  model = svm.SVR()\n",
        "  \n",
        "  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=4, verbose=2)\n",
        "  \n",
        "  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)\n",
        "\n",
        "  gs.fit(X[i:j], Y[i:j])\n",
        "  \n",
        "  best = gs.best_estimator_\n",
        "  predictions = best.predict(X[j:k])                         \n",
        "      \n",
        "  mae = sklm.mean_absolute_error(Y[j:k], predictions)\n",
        "  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))\n",
        "  nrmse = rmse / np.std(Y[j:k])\n",
        "  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)\n",
        "  \n",
        "  res = {\n",
        "    'params': gs.best_params_,\n",
        "    'results': {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'NRMSE': nrmse,\n",
        "        'HR': hr,\n",
        "    },\n",
        "  }\n",
        "\n",
        "  print_json(res)\n",
        "  store(res, 'results/', 'svm_multi_best_params' if isMulti else 'svm_uni_best_params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scKSmSyk5Awm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def support_vector_machine(data, isMulti):\n",
        "  global result_data\n",
        "  \n",
        "  name = \"SVM Multivariate\" if isMulti else \"SVM Univariate\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
        "\n",
        "  expected, observed, times = [], [], []\n",
        "  \n",
        "  model = svm.SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
        "  \n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    model.fit(X[i:j], Y[i:j])\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(model.predict(X[j:k]))\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3dQ_nM_TgDC",
        "colab_type": "text"
      },
      "source": [
        "## RNN\n",
        "\n",
        "The optimzation was based on [How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH_62Q8G2s9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import SimpleRNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO2XJF3A7lB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_rnn(input_shape):\n",
        "  def create(n=50, optimizer='adam', activation='relu'):\n",
        "    model = Sequential()\t\t\n",
        "\n",
        "    model.add(SimpleRNN(n, activation=activation, input_shape=input_shape))\t\t\n",
        "    model.add(Dense(1))\t\t\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics = [\"accuracy\"])\n",
        "    return model\t\t\n",
        "\n",
        "  return create"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRYgTLXYNA7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_grid(data, isMulti):\t\t\n",
        "  global result_data\t\t\n",
        "\n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "\n",
        "  cv=[(slice(None), slice(None))]\t\t\n",
        "  param_grid = {\t\t\n",
        "    'optimizer': ['Adam', 'Adamax'],\n",
        "    'activation': ['relu', 'sigmoid'],\n",
        "    'n': [50, 75, 100],\n",
        "    'batch_size': [16, 32, 64],\t\t\n",
        "    'epochs': [15, 20]\t\t\n",
        "  }\t\n",
        "\n",
        "  model = KerasClassifier(build_fn=create_rnn((X.shape[1], X.shape[2])), verbose=0)\n",
        "\n",
        "  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=4, verbose=2)\t\t\n",
        "\n",
        "  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)\t\t\n",
        "\n",
        "  gs.fit(X[i:j], Y[i:j])\t\t\n",
        "\n",
        "  best = gs.best_estimator_\t\t\n",
        "  predictions = best.predict(X[j:k])                         \t\t\n",
        "\n",
        "  mae = sklm.mean_absolute_error(Y[j:k], predictions)\t\t\n",
        "  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))\t\t\n",
        "  nrmse = rmse / np.std(Y[j:k])\t\t\n",
        "  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)\t\t\n",
        "\n",
        "  res = {\n",
        "    'params': gs.best_params_,\n",
        "    'results': {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'NRMSE': nrmse,\n",
        "        'HR': hr,\n",
        "    },\n",
        "  }\n",
        "\n",
        "  print_json(res)\n",
        "  store(res, 'results/', 'rnn_multi_best_params' if isMulti else 'rnn_uni_best_params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st9EurMVT5gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn (data, isMulti): \n",
        "  global result_data\n",
        "  \n",
        "  name = \"RNN Multivariate\" if isMulti else \"RNN Univariate\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  \n",
        "  expected, observed, times = [], [], []\n",
        "  \n",
        "  model = create_rnn((X.shape[1], X.shape[2]))()\n",
        "  \n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    hist = model.fit(X[i:j], Y[i:j], validation_split=0.2, batch_size=64, epochs=15, verbose=0)\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(model.predict(X[j:k]))\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      plot_history(hist, f\"{name} ({str(len(times)).zfill(2)} of {len(pointers)})\")\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Nq3PsMTjYc",
        "colab_type": "text"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTbbtAki29wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YwuQGFp7w5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_lstm(input_shape):\n",
        "  def create(n=50, optimizer='adam', activation='relu'):\n",
        "    model = Sequential()\t\t\n",
        "\n",
        "    model.add(LSTM(n, activation=activation, input_shape=input_shape))\t\t\n",
        "    model.add(Dense(1))\t\t\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics = [\"accuracy\"])\t\n",
        "\n",
        "    return model\n",
        "\n",
        "  return create"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrdfXg73NSik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_grid(data, isMulti):\t\t\n",
        "  global result_data\t\t\n",
        "        \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "\n",
        "  cv=[(slice(None), slice(None))]\n",
        "  param_grid = {\t\t\n",
        "    'optimizer': ['Adam', 'Adamax'],\n",
        "    'activation': ['relu', 'sigmoid'],\n",
        "    'n': [50, 75, 100],\n",
        "    'batch_size': [16, 32, 64],\t\t\n",
        "    'epochs': [15, 20]\t\t\n",
        "  }\n",
        "      \n",
        "  model = KerasClassifier(build_fn=create_lstm((X.shape[1], X.shape[2])), verbose=0)\t\t\n",
        "    \n",
        "  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=4, verbose=2)\t\t\n",
        "      \n",
        "  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)\t\t\n",
        "    \n",
        "  gs.fit(X[i:j], Y[i:j])\n",
        "        \n",
        "  best = gs.best_estimator_\t\n",
        "  predictions = best.predict(X[j:k])                         \t\t\n",
        "          \n",
        "  mae = sklm.mean_absolute_error(Y[j:k], predictions)\t\t\n",
        "  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))\t\t\n",
        "  nrmse = rmse / np.std(Y[j:k])\t\t\n",
        "  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)\t\t\n",
        "        \n",
        "  res = {\n",
        "    'params': gs.best_params_,\n",
        "    'results': {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'NRMSE': nrmse,\n",
        "        'HR': hr,\n",
        "    },\n",
        "  }\n",
        "\n",
        "  print_json(res)\n",
        "  store(res, 'results/', 'lstm_multi_best_params' if isMulti else 'lstm_uni_best_params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGyRz8GzTp4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm (data, isMulti): \n",
        "  global result_data\n",
        "  \n",
        "  name = \"LSTM Multivariate\" if isMulti else \"LSTM Univariate\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "  \n",
        "  expected, observed, times = [], [], []\n",
        "  \n",
        "  model = create_lstm((X.shape[1], X.shape[2]))()\n",
        "  \n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    hist = model.fit(X[i:j], Y[i:j], validation_split=0.2, batch_size=64, epochs=15, verbose=0)\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(model.predict(X[j:k]))\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      plot_history(hist, f\"{name} ({str(len(times)).zfill(2)} of {len(pointers)})\")\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhaufggBRABt",
        "colab_type": "text"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP_hAZNu3CS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import GRU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1AKkTBu79Om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_gru(input_shape):\n",
        "  def create(n=50, optimizer='adam', activation='relu'):\n",
        "    model = Sequential()\t\t\n",
        "\n",
        "    model.add(GRU(n, activation=activation, input_shape=input_shape))\t\t\n",
        "    model.add(Dense(1))\t\t\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics = [\"accuracy\"])\t\t\n",
        "\n",
        "    return model\t\t\n",
        "    \n",
        "  return create"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ETV7D_7NtpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru_grid(data, isMulti):\t\t\n",
        "  global result_data\t\t\n",
        "        \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "        \n",
        "  cv=[(slice(None), slice(None))]\t\t\n",
        "  param_grid = {\t\t\n",
        "    'optimizer': ['Adam', 'Adamax'],\n",
        "    'activation': ['relu', 'sigmoid'],\n",
        "    'n': [50, 75, 100],\n",
        "    'batch_size': [16, 32, 64],\t\t\n",
        "    'epochs': [15, 20]\t\t\n",
        "  }\t\t\n",
        "        \n",
        "  model = KerasClassifier(build_fn=create_gru((X.shape[1], X.shape[2])), verbose=0)\n",
        "    \n",
        "  gs = skl.model_selection.GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=cv, n_jobs=4, verbose=2)\t\t\n",
        "      \n",
        "  i, j, k = 0, int(len(X) * (1 - TEST_SPLIT)), len(X)\t\t\n",
        "    \n",
        "  gs.fit(X[i:j], Y[i:j])\t\t\n",
        "      \n",
        "  best = gs.best_estimator_\t\t\n",
        "  predictions = best.predict(X[j:k])                         \t\t\n",
        "          \n",
        "  mae = sklm.mean_absolute_error(Y[j:k], predictions)\t\t\n",
        "  rmse = np.sqrt(sklm.mean_squared_error(Y[j:k], predictions))\t\t\n",
        "  nrmse = rmse / np.std(Y[j:k])\t\t\n",
        "  hr = evaluate_precision_hit_ratio(Y[j:k], predictions)\t\t\n",
        "      \n",
        "  res = {\n",
        "    'params': gs.best_params_,\n",
        "    'results': {\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'NRMSE': nrmse,\n",
        "        'HR': hr,\n",
        "    },\n",
        "  }\n",
        "\n",
        "  print_json(res)\n",
        "  store(res, 'results/', 'gru_multi_best_params' if isMulti else 'gru_uni_best_params')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD1GwF_b9P2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gru (data, isMulti): \n",
        "  global result_data\n",
        "  \n",
        "  name = \"GRU Multivariate\" if isMulti else \"GRU Univariate\"\n",
        "  \n",
        "  X, Y = generate_dataset(data, isMulti, FLOW_INTERVAL, N_STEPS, N_FUTURE, NORMALIZE, VERBOSITY)\n",
        "\n",
        "  expected, observed, times = [], [], []\n",
        "  \n",
        "  model = create_gru((X.shape[1], X.shape[2]))()\n",
        "  \n",
        "  pointers = split_dataset(len(X), SET_SPLIT, TEST_SPLIT)\n",
        "  \n",
        "  for i, j, k in pointers:\n",
        "    start = tm.time()\n",
        "    \n",
        "    hist = model.fit(X[i:j], Y[i:j], validation_split=0.2, batch_size=64, epochs=15, verbose=0)\n",
        "    \n",
        "    expected.append(Y[j:k])\n",
        "    observed.append(model.predict(X[j:k]))\n",
        "    times.append(tm.time() - start)\n",
        "    \n",
        "    if VERBOSITY:\n",
        "      plot_history(hist, f\"{name} ({str(len(times)).zfill(2)} of {len(pointers)})\")\n",
        "    \n",
        "  result_data['results'][name] = evaluate(expected, observed, times, name)\n",
        "  \n",
        "  if VERBOSITY:\n",
        "    plot_prediction(expected, observed, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7RYTwKXkP4o",
        "colab_type": "text"
      },
      "source": [
        "# Plot Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOj9DSrIHhiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_performance(metric, y_label, title):\n",
        "  \"\"\" Plot Performance\n",
        "  \n",
        "  Plot a bar graph of the performance of some metric\n",
        "  \n",
        "  Arguments:\n",
        "    metric: the name of the property of the metric\n",
        "    y_label: the name of the label of the metric\n",
        "    title: the title of the plot\n",
        "  \"\"\"\n",
        "  \n",
        "  path = f\"{PATH}plots/performance/{title} Performance Bar\"\n",
        "  \n",
        "  models = tuple(result_data['results'].keys())\n",
        "  y_pos = np.arange(len(models))\n",
        "  performance = [v[metric] for v in result_data['results'].values()]\n",
        "\n",
        "  plt.rcdefaults()\n",
        "  plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "  plt.xticks(y_pos, models, rotation=90)\n",
        "  plt.ylabel(y_label)\n",
        "  plt.title(title)\n",
        "\n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.savefig(path + \".pdf\")\n",
        "  \n",
        "  if SHOW_PLOT:\n",
        "    plt.show()\n",
        "    \n",
        "  plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhvtEPTrH5TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_performance_improved(metric, y_label, title):\n",
        "  \"\"\" Plot Performance Improved\n",
        "  \n",
        "  Plot a box graph of the performance of some metric\n",
        "  \n",
        "  Arguments:\n",
        "    metric: the name of the property of the metric\n",
        "    y_label: the name of the label of the metric\n",
        "    title: the title of the plot\n",
        "  \"\"\"\n",
        "  \n",
        "  path = f\"{PATH}plots/performance/{title} Performance Boxes\"\n",
        "  \n",
        "  fig, ax_plot = plt.subplots()\n",
        "  \n",
        "  ax_plot.set_title(title)\n",
        "  ax_plot.set_xlabel(y_label)\n",
        "  ax_plot.set_ylabel('Model')\n",
        "  \n",
        "  bplot = ax_plot.boxplot([v['raw'][metric] for v in result_data['results'].values()], vert=False)\n",
        "  ax_plot.set_yticklabels(list(result_data['results'].keys()))\n",
        "  \n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.savefig(path + \".pdf\")\n",
        "  \n",
        "  if SHOW_PLOT:\n",
        "    plt.show()\n",
        "    \n",
        "  plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRC8liDUH7QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_precision_bucket ():\n",
        "  \"\"\" Plot Precision Bucket \n",
        "  \n",
        "  Plot a stack box graph of the precision mesuared by the buckets.\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  path = f\"{PATH}plots/precision\"\n",
        "  \n",
        "  N = len(result_data['results'])\n",
        "    \n",
        "  ind = np.arange(N)    # the x locations for the groups\n",
        "  width = 0.35       # the width of the bars: can also be len(x) sequence\n",
        "  \n",
        "  pre = []\n",
        "  bott = []\n",
        "  \n",
        "  models = list(result_data['results'].keys())\n",
        "\n",
        "  n_buckets = len(result_data['results'][models[0]]['PRE'])\n",
        "    \n",
        "  for i in range(n_buckets):\n",
        "    pre.append([v[\"PRE\"][i] for v in result_data['results'].values()])\n",
        "    \n",
        "    if i == 0:\n",
        "      bott.append([0] * N)\n",
        "    else:\n",
        "      bott.append([bott[i-1][j] + pre[i-1][j]  for j in range(N)])\n",
        "  \n",
        "  p = []\n",
        "  leg_lin = []\n",
        "  leg_lab = []\n",
        "  \n",
        "  for i in range(n_buckets):\n",
        "    _p = plt.bar(ind, tuple(pre[i]), width, bottom=tuple(bott[i]))\n",
        "    \n",
        "    leg_lin.append(_p[0])\n",
        "    leg_lab.append(f\"Bucket of {2**i}\")\n",
        "    p.append(_p)\n",
        "\n",
        "  plt.ylabel('Scores')\n",
        "  plt.title('Precision by model and bucket')\n",
        "  plt.xticks(ind, list(result_data['results'].keys()), rotation=90)\n",
        "  plt.yticks(np.arange(0, 1.05, 0.05))\n",
        "  plt.legend(tuple(leg_lin), tuple(leg_lab))\n",
        "  \n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.savefig(path + \".pdf\")\n",
        "\n",
        "  if SHOW_PLOT:\n",
        "    plt.show()\n",
        "\n",
        "  plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1QmFwC1k2NO",
        "colab_type": "text"
      },
      "source": [
        "# Comparison Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdN_JTyQISlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results_comparison(name, xlabel, xticks, metric):\n",
        "  path = f\"{PATH}plots/comparison/{name.lower().replace(' ', '_')}_{metric.lower()}\"\n",
        "  models = [*comparison_data[0]['results']]\n",
        "  \n",
        "  for model in models:\n",
        "    datapoints = [result['results'][model][metric] for result in comparison_data]\n",
        "    plt.plot(datapoints) \n",
        "\n",
        "  plt.title(name)\n",
        "  plt.ylabel(metric)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.xticks(np.arange(len(xticks)), xticks)\n",
        "  plt.legend(models, loc='upper left')\n",
        "  plt.rcdefaults()\n",
        "\n",
        "  plt.savefig(path + \".png\", bbox_inches='tight')\n",
        "  plt.savefig(path + \".pdf\")\n",
        "\n",
        "  if SHOW_PLOT:\n",
        "    plt.show()\n",
        "    \n",
        "  plt.close('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVG-q8fvk32O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_results_by_window_split(values):\n",
        "  global SET_SPLIT\n",
        "  global VERBOSITY\n",
        "  global result_data\n",
        "  global comparison_data\n",
        "  \n",
        "  aux = SET_SPLIT\n",
        "  \n",
        "  VERBOSITY = False\n",
        "  \n",
        "  result_data = {\n",
        "      'results': {},\n",
        "      'meta': {}\n",
        "  }\n",
        "  \n",
        "  comparison_data = []\n",
        "\n",
        "  for value in values:\n",
        "    start = tm.time()\n",
        "    \n",
        "    SET_SPLIT = value\n",
        "\n",
        "#     random_guess_univariate(data)\n",
        "    moving_average(data)\n",
        "    naive(data)\n",
        "#     logistic_regression(data, False)\n",
        "#     logistic_regression(data, True)\n",
        "    random_forest(data, False)\n",
        "    random_forest(data, True)\n",
        "    support_vector_machine(data, False)\n",
        "    support_vector_machine(data, True)\n",
        "    rnn(data, False)\n",
        "    rnn(data, True)\n",
        "    lstm(data, False)\n",
        "    lstm(data, True)\n",
        "    gru(data, False)\n",
        "    gru(data, True)\n",
        "    \n",
        "    comparison_data.append(copy.deepcopy(result_data))\n",
        "    \n",
        "    print(f\"({len(comparison_data)} of {len(values)}) Finished Running with SET_SPLIT {value} in {tm.time() - start} seconds\")\n",
        "\n",
        "  store_comparisons('_window_split_comparison')\n",
        "  \n",
        "  SET_SPLIT = aux"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Y3gTSGI4uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_results_by_seeable_past(values):\n",
        "  global SEEABLE_PAST\n",
        "  global N_STEPS\n",
        "  global VERBOSITY\n",
        "  global result_data\n",
        "  global comparison_data\n",
        "  \n",
        "  aux = SEEABLE_PAST\n",
        "  \n",
        "  VERBOSITY = False\n",
        "  \n",
        "  result_data = {\n",
        "      'results': {},\n",
        "      'meta': {}\n",
        "  }\n",
        "  \n",
        "  comparison_data = []\n",
        "\n",
        "  for value in values:\n",
        "    start = tm.time()\n",
        "    \n",
        "    SEEABLE_PAST = value\n",
        "    N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL\n",
        "\n",
        "#     random_guess_univariate(data)\n",
        "    moving_average(data)\n",
        "    naive(data)\n",
        "#     logistic_regression(data, False)\n",
        "#     logistic_regression(data, True)\n",
        "    random_forest(data, False)\n",
        "    random_forest(data, True)\n",
        "    support_vector_machine(data, False)\n",
        "    support_vector_machine(data, True)\n",
        "    rnn(data, False)\n",
        "    rnn(data, True)\n",
        "    lstm(data, False)\n",
        "    lstm(data, True)\n",
        "    gru(data, False)\n",
        "    gru(data, True)\n",
        "    \n",
        "    comparison_data.append(copy.deepcopy(result_data))\n",
        "    \n",
        "    print(f\"({len(comparison_data)} of {len(values)}) Finished Running with SEEABLE_PAST {value} in {tm.time() - start} seconds\")\n",
        "\n",
        "  store_comparisons('_seeable_past_comparison')\n",
        "  \n",
        "  SEEABLE_PAST = aux\n",
        "  N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h35ErSHQH85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_results_by_flow_interval(values):\n",
        "  global FLOW_INTERVAL\n",
        "  global N_STEPS\n",
        "  global N_FUTURE\n",
        "  global DAY_SIZE\n",
        "  global WEEK_SIZE\n",
        "  global VERBOSITY\n",
        "  global result_data\n",
        "  global comparison_data\n",
        "  \n",
        "  aux = FLOW_INTERVAL\n",
        "  \n",
        "  VERBOSITY = False\n",
        "  \n",
        "  result_data = {\n",
        "      'results': {},\n",
        "      'meta': {}\n",
        "  }\n",
        "  \n",
        "  comparison_data = []\n",
        "\n",
        "  for value in values:\n",
        "    start = tm.time()\n",
        "    \n",
        "    FLOW_INTERVAL = value\n",
        "    N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL\n",
        "    N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL\n",
        "    DAY_SIZE = (24 * 3600) // FLOW_INTERVAL  \n",
        "    WEEK_SIZE = 7 * DAY_SIZE\n",
        "\n",
        "#     random_guess_univariate(data)\n",
        "    moving_average(data)\n",
        "    naive(data)\n",
        "#     logistic_regression(data, False)\n",
        "#     logistic_regression(data, True)\n",
        "    random_forest(data, False)\n",
        "    random_forest(data, True)\n",
        "    support_vector_machine(data, False)\n",
        "    support_vector_machine(data, True)\n",
        "    rnn(data, False)\n",
        "    rnn(data, True)\n",
        "    lstm(data, False)\n",
        "    lstm(data, True)\n",
        "    gru(data, False)\n",
        "    gru(data, True)\n",
        "    \n",
        "    comparison_data.append(copy.deepcopy(result_data))\n",
        "    \n",
        "    print(f\"({len(comparison_data)} of {len(values)}) Finished Running with FLOW_INTERVAL {value} in {tm.time() - start} seconds\")\n",
        "\n",
        "  store_comparisons('_flow_interval_comparison')\n",
        "  \n",
        "  FLOW_INTERVAL = aux\n",
        "  N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL\n",
        "  N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL\n",
        "  DAY_SIZE = (24 * 3600) // FLOW_INTERVAL  \n",
        "  WEEK_SIZE = 7 * DAY_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wC3yGkZQGFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_results_by_predict_in_future(values):\n",
        "  global PREDICT_IN_FUTURE\n",
        "  global N_FUTURE\n",
        "  global VERBOSITY\n",
        "  global result_data\n",
        "  global comparison_data\n",
        "  \n",
        "  aux = PREDICT_IN_FUTURE\n",
        "  \n",
        "  VERBOSITY = False\n",
        "  \n",
        "  result_data = {\n",
        "      'results': {},\n",
        "      'meta': {}\n",
        "  }\n",
        "  \n",
        "  comparison_data = []\n",
        "\n",
        "  for value in values:\n",
        "    start = tm.time()\n",
        "    \n",
        "    PREDICT_IN_FUTURE = value\n",
        "    N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL\n",
        "\n",
        "#     random_guess_univariate(data)\n",
        "    moving_average(data)\n",
        "    naive(data)\n",
        "#     logistic_regression(data, False)\n",
        "#     logistic_regression(data, True)\n",
        "    random_forest(data, False)\n",
        "    random_forest(data, True)\n",
        "    support_vector_machine(data, False)\n",
        "    support_vector_machine(data, True)\n",
        "    rnn(data, False)\n",
        "    rnn(data, True)\n",
        "    lstm(data, False)\n",
        "    lstm(data, True)\n",
        "    gru(data, False)\n",
        "    gru(data, True)\n",
        "    \n",
        "    comparison_data.append(copy.deepcopy(result_data))\n",
        "    \n",
        "    print(f\"({len(comparison_data)} of {len(values)}) Finished Running with PREDICT_IN_FUTURE {value} in {tm.time() - start} seconds\")\n",
        "\n",
        "  store_comparisons('_predict_future_comparison')\n",
        "  \n",
        "  PREDICT_IN_FUTURE = aux\n",
        "  N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PypQpgeb3Nu",
        "colab_type": "text"
      },
      "source": [
        "# Train&Test\n",
        "\n",
        "Run all the models and store the results at the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IURi5r5HV5oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Parameters\n",
        "\n",
        "SEEABLE_PAST = 180 # in minutes\n",
        "\n",
        "PREDICT_IN_FUTURE = 15 # in minutes\n",
        "\n",
        "FLOW_INTERVAL = 450 # the interval size for each flow\n",
        "\n",
        "NORMALIZE = False #Decide if we gonna use normalized flow and speed values, or not\n",
        "\n",
        "SET_SPLIT = 0.65\n",
        "\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE_V1sw0V2DL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derivated Model Parameters\n",
        "\n",
        "N_STEPS = SEEABLE_PAST * 60 // FLOW_INTERVAL # the number of flows to see in the past\n",
        "\n",
        "N_FUTURE = PREDICT_IN_FUTURE * 60 // FLOW_INTERVAL # how much in the future we want to predict (0 = predict the flow on the next 5 minutes)\n",
        "\n",
        "DAY_SIZE = (24 * 60 * 60) // FLOW_INTERVAL  \n",
        "\n",
        "WEEK_SIZE = (7 * 24 * 60 * 60) // FLOW_INTERVAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnwtPTLWVHLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_data = {\n",
        "    'results': {},\n",
        "    'meta': {}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI45Wr_TVIqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comparison_data = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rN7dqj_R49N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = retrieve_data(VERBOSITY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWyHB9uiLGyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = clean_data(all_data, VERBOSITY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkzblQkQuZIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analise_flow(data, FLOW_INTERVAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXmwQlAOO_zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_forest_grid(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DNp5XV7fkFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_forest_grid(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcwtR-TuODBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "support_vector_machine_grid(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl1iUSs1OEge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "support_vector_machine_grid(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UWLe-8QZtUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logistic_regression_grid(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MjjSbWLZ5o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logistic_regression_grid(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4Y7Y7x7OGIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rnn_grid(data, False)\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2nH8jrmOHY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rnn_grid(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CJh4eqDOInH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_grid(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djbiudehOJ5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_grid(data, True)\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR7RZ93cOK-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_grid(data, False)\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQVE4Ov3OMFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_grid(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqSzsHvOF-NI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#random_guess_univariate(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOZdw4rGGbiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moving_average(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7YKxLnEGbsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "naive(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT8eDOklsVK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logistic_regression(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k--_MoO6sZdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logistic_regression(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTtHnOIvGb10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "68e70aae-c3bb-40c2-b768-cda872cbe21a"
      },
      "source": [
        "random_forest(data, False)\n",
        "\n",
        "# RF Univariate Final Result:\n",
        "# \tTotal Time: 43s\n",
        "# \tRMSE: 0.0801421940190332\n",
        "# \tNRMSE: 0.3637459354493491\n",
        "# \tMAE: 0.0578222441743975\n",
        "# \tHit Ratio: 68.8995768711515%\n",
        "\n",
        "\n",
        "# RF Univariate Final Result:\n",
        "# \tTotal Time: 43s\n",
        "# \tRMSE: 7.516542869550363\n",
        "# \tNRMSE: 0.36293234361818416\n",
        "# \tMAE: 5.432782458260094\n",
        "# \tHit Ratio: 68.955390365175%"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1/4) Test Size: 2292, Time: 10.710024118423462s\n",
            "\tRMSE: 7.46183480035312\n",
            "\tNRMSE: 0.35950661316077875\n",
            "\tMAE: 5.199849195961107\n",
            "\tHit Ratio: 64.09249563699827%\n",
            "(2/4) Test Size: 2292, Time: 10.72785234451294s\n",
            "\tRMSE: 7.828118811110057\n",
            "\tNRMSE: 0.37359975617064095\n",
            "\tMAE: 5.692362565445026\n",
            "\tHit Ratio: 71.68411867364746%\n",
            "(3/4) Test Size: 2292, Time: 10.76230263710022s\n",
            "\tRMSE: 7.162668789176279\n",
            "\tNRMSE: 0.3453812644202035\n",
            "\tMAE: 5.294600930773706\n",
            "\tHit Ratio: 72.12041884816755%\n",
            "(4/4) Test Size: 1590, Time: 10.859924793243408s\n",
            "\tRMSE: 7.613549077561994\n",
            "\tNRMSE: 0.37324174072111355\n",
            "\tMAE: 5.544317140860537\n",
            "\tHit Ratio: 67.9245283018868%\n",
            "\n",
            "RF Univariate Final Result:\n",
            "\tTotal Time: 43s\n",
            "\tRMSE: 7.516542869550363\n",
            "\tNRMSE: 0.36293234361818416\n",
            "\tMAE: 5.432782458260094\n",
            "\tHit Ratio: 68.955390365175%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJYRWje8Gb8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_forest(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR-u7mO_GcCQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "5ccc6a0c-81e4-4410-ec92-e11edf85522c"
      },
      "source": [
        "support_vector_machine(data, False)\n",
        "\n",
        "# SVM Univariate Final Result:\n",
        "# \tTotal Time: 2s\n",
        "# \tRMSE: 0.10341455 413116515\n",
        "# \tNRMSE: 0.46950987978895825\n",
        "# \tMAE: 0.08529601908528409\n",
        "# \tHit Ratio: 62.87443610260463%\n",
        "\n",
        "# SVM Univariate Final Result:\n",
        "# \tTotal Time: 33s\n",
        "# \tRMSE: 7.548441410060743\n",
        "# \tNRMSE: 0.3644439863724624\n",
        "# \tMAE: 5.456924860407852\n",
        "# \tHit Ratio: 68.1847854720274%"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1/4) Test Size: 2292, Time: 8.340087652206421s\n",
            "\tRMSE: 7.4782721478351535\n",
            "\tNRMSE: 0.3602985544568167\n",
            "\tMAE: 5.240242414243696\n",
            "\tHit Ratio: 63.39441535776614%\n",
            "(2/4) Test Size: 2292, Time: 8.373342514038086s\n",
            "\tRMSE: 7.929664508852752\n",
            "\tNRMSE: 0.3784460607340062\n",
            "\tMAE: 5.796422200013273\n",
            "\tHit Ratio: 70.6369982547993%\n",
            "(3/4) Test Size: 2292, Time: 8.305297374725342s\n",
            "\tRMSE: 7.240859861791336\n",
            "\tNRMSE: 0.34915160929039624\n",
            "\tMAE: 5.378339802283332\n",
            "\tHit Ratio: 71.16055846422339%\n",
            "(4/4) Test Size: 1590, Time: 8.055071592330933s\n",
            "\tRMSE: 7.54496912176373\n",
            "\tNRMSE: 0.3698797210086304\n",
            "\tMAE: 5.412695025091112\n",
            "\tHit Ratio: 67.54716981132076%\n",
            "\n",
            "SVM Univariate Final Result:\n",
            "\tTotal Time: 33s\n",
            "\tRMSE: 7.548441410060743\n",
            "\tNRMSE: 0.3644439863724624\n",
            "\tMAE: 5.456924860407852\n",
            "\tHit Ratio: 68.1847854720274%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr4uwc6OGcTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "support_vector_machine(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhxMxpGIGcYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rnn(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA4broRMGcRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rnn(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UoTWDJpGcOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwR2yDVkGcLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsTARwY0GcI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru(data, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HrdsNZqGcGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru(data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm1wfgScJlHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store_results()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKOkVgy-viQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot_precision_bucket()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7nGtfoDjRtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_improved('TIME', 'Seconds', 'Training Time Comparison')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfkT6lp1jhfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_improved('RMSE', 'RMSE', 'Root Mean Square Error Comparison')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_139ETyjiDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_improved('NRMSE', 'NRMSE', 'Normalized Root Mean Square Error Comparison')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTENlZJRjinW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_improved('MAE', 'MAE', 'Max Absolute Error Comparison')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgzZvkngeY2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_performance_improved('HR', 'Percentage', 'Hit Ratio Comparison')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSXAVmzYV0VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load_comparison(\"1571844839_predict_future_comparison_slim\")\n",
        "# VERBOSITY = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n384b75iQ6Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_futures = [15, 30, 45, 60]\n",
        "compare_results_by_predict_in_future(predict_futures)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoCh5F7JRAhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Predict Future for Training Comparison', 'Time in the Future in Minutes', predict_futures, 'NRMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0edllKHwRAp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Predict Future for Training Comparison', 'Time in the Future in Minutes', predict_futures, 'RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNY39RCERAyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Predict Future for Training Comparison', 'Time in the Future in Minutes', predict_futures, 'MAE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGrQ0gM0KhLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flow_intervals = [150, 300, 450]\n",
        "compare_results_by_flow_interval(flow_intervals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtZJbhadKjVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Flow Interval for Training Comparison', 'Flow Size in Seconds', flow_intervals, 'NRMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o28WE_M3KkBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Flow Interval for Training Comparison', 'Flow Size in Seconds', flow_intervals, 'RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID4jupZOKkdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Flow Interval for Training Comparison', 'Flow Size in Seconds', flow_intervals, 'MAE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOdpUrt2Qbwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seeable_pasts = [60, 120, 180, 210, 240, 270, 300, 360, 420]\n",
        "compare_results_by_seeable_past(seeable_pasts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGoj6VvhSXhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Seeable Past for Training Comparison', 'Seeable Past in Seconds', seeable_pasts, 'NRMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmwAO9MTSXq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Seeable Past for Training Comparison', 'Seeable Past in Seconds', seeable_pasts, 'RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSRgAREWSXzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Seeable Past for Training Comparison', 'Seeable Past in Seconds', seeable_pasts, 'MAE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cRR0WElOJdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_splits = [0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85]\n",
        "compare_results_by_window_split(window_splits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHqYGnwuOJ1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Windows Size for Training Comparison', 'Window Size', window_splits, 'NRMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnT7vcK7Hl8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Windows Size for Training Comparison', 'Window Size', window_splits, 'RMSE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4SuhASgHnyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_results_comparison('Windows Size for Training Comparison', 'Window Size', window_splits, 'MAE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBjqtHAo_aFw",
        "colab_type": "text"
      },
      "source": [
        "# Observations:\n",
        "\n",
        "+ For the evaluation of the RNN and it's variations was used the Walking Forward methodology so that we had many test sessions and all training sessions where the same size [[1]](https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9)\n",
        "+ To remove the cross-validation of the GridSearchCV we based on the answer in [scikit learn discussion - allow GridSearchCV to work with params={} or cv=1](https://github.com/scikit-learn/scikit-learn/issues/2048)\n",
        "+ Grid Search on Keras was based on the article [How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)"
      ]
    }
  ]
}